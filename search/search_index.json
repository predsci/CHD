{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Coronal Hole Detection Project For Python files visit the CHD Git repository . Project Outline Data Collection Image Pre-Processing: PSF Deconvolution Limb-Brightening Correction Inter-Instrument Transformation Coronal Hole Detection Mapping Project Pipeline Some sort of graphic here...","title":"Home"},{"location":"#welcome-to-the-coronal-hole-detection-project","text":"For Python files visit the CHD Git repository .","title":"Welcome to the Coronal Hole Detection Project"},{"location":"#project-outline","text":"Data Collection Image Pre-Processing: PSF Deconvolution Limb-Brightening Correction Inter-Instrument Transformation Coronal Hole Detection Mapping","title":"Project Outline"},{"location":"#project-pipeline","text":"Some sort of graphic here...","title":"Project Pipeline"},{"location":"about/","text":"About the Project Contact Cooper Downs: cdowns@predsci.com James Turtle: jturtle@predsci.com Jon Linker: linkerj@predsci.com Tamar Ervin (Intern): tamar@predsci.com","title":"About the Project"},{"location":"about/#about-the-project","text":"","title":"About the Project"},{"location":"about/#contact","text":"Cooper Downs: cdowns@predsci.com James Turtle: jturtle@predsci.com Jon Linker: linkerj@predsci.com Tamar Ervin (Intern): tamar@predsci.com","title":"Contact"},{"location":"chd/chd/","text":"Coronal Hole Detection Coronal Hole Detection is carried out using a two-threshold region growing algorithm. Algorithm 1 2 3 4 5 6 7 8 9 10 11 12 13 \"\"\" python wrapper function for fortran algorithm @param image_data: EUV Image data for detection @param use_chd: matrix of size (nx,ny) which contains 1's where there is valid image data, and non-zero values for areas with invalid/no IMG data. @param nx, ny: image dimensions @param t1, t2: threshold values @param nc: pixel connectivity parameter - number of consecutive pixels needed for connectivity @param iters: maximum number of iterations allowed @return ezseg_output: segmentation map where 0 marks a detection @return iters_used: number of iterations preformed \"\"\" ezseg_output , iters_used = ezsegwrapper . ezseg ( np . log10 ( image_data ), use_chd , nx , ny , t1 , t2 , nc , iters ) 1.) viable pixels are checked to see if the intensity level is below threshold 1 if so, pixel is marked 2.) in each iteration, pixels are checked if their intensity is between threshold 1 and 2, and if they have the required number of connected pixels if so, pixel is marked 3.) continues until no more pixels are marked Example Maps Example minimum intensity merge maps with and without Coronal Hole Detection overlaid. You can click on image titles to enlarge images. Maps with both methods of minimum intensity merge are shown. Minimum Intensity Merge with Two Threshold Mu Cutoff Values April 11, 2011 EUV Map Combined EUV/CHD Map May 15, 2011 EUV Map Combined EUV/CHD Map July 21, 2011 EUV Map Combined EUV/CHD Map August 18, 2011 EUV Map Combined EUV/CHD Map October 1, 2011 EUV Map Combined EUV/CHD Map Minimum Intensity Merge based on Maximum Mu Value April 11, 2011 EUV Map Combined EUV/CHD Map May 15, 2011 EUV Map Combined EUV/CHD Map July 21, 2011 EUV Map Combined EUV/CHD Map August 18, 2011 EUV Map Combined EUV/CHD Map October 1, 2011 EUV Map Combined EUV/CHD Map","title":"CH Detection"},{"location":"chd/chd/#coronal-hole-detection","text":"Coronal Hole Detection is carried out using a two-threshold region growing algorithm.","title":"Coronal Hole Detection"},{"location":"chd/chd/#algorithm","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 \"\"\" python wrapper function for fortran algorithm @param image_data: EUV Image data for detection @param use_chd: matrix of size (nx,ny) which contains 1's where there is valid image data, and non-zero values for areas with invalid/no IMG data. @param nx, ny: image dimensions @param t1, t2: threshold values @param nc: pixel connectivity parameter - number of consecutive pixels needed for connectivity @param iters: maximum number of iterations allowed @return ezseg_output: segmentation map where 0 marks a detection @return iters_used: number of iterations preformed \"\"\" ezseg_output , iters_used = ezsegwrapper . ezseg ( np . log10 ( image_data ), use_chd , nx , ny , t1 , t2 , nc , iters ) 1.) viable pixels are checked to see if the intensity level is below threshold 1 if so, pixel is marked 2.) in each iteration, pixels are checked if their intensity is between threshold 1 and 2, and if they have the required number of connected pixels if so, pixel is marked 3.) continues until no more pixels are marked","title":"Algorithm"},{"location":"chd/chd/#example-maps","text":"Example minimum intensity merge maps with and without Coronal Hole Detection overlaid. You can click on image titles to enlarge images. Maps with both methods of minimum intensity merge are shown.","title":"Example Maps"},{"location":"chd/chd/#minimum-intensity-merge-with-two-threshold-mu-cutoff-values","text":"April 11, 2011 EUV Map Combined EUV/CHD Map May 15, 2011 EUV Map Combined EUV/CHD Map July 21, 2011 EUV Map Combined EUV/CHD Map August 18, 2011 EUV Map Combined EUV/CHD Map October 1, 2011 EUV Map Combined EUV/CHD Map","title":"Minimum Intensity Merge with Two Threshold Mu Cutoff Values"},{"location":"chd/chd/#minimum-intensity-merge-based-on-maximum-mu-value","text":"April 11, 2011 EUV Map Combined EUV/CHD Map May 15, 2011 EUV Map Combined EUV/CHD Map July 21, 2011 EUV Map Combined EUV/CHD Map August 18, 2011 EUV Map Combined EUV/CHD Map October 1, 2011 EUV Map Combined EUV/CHD Map","title":"Minimum Intensity Merge based on Maximum Mu Value"},{"location":"chd/f2py/","text":"Creating Wrapper Function for Ezseg Algorithm How to create a wrapper function for Fortran code: more information can be found here 1.) python -m numpy.f2py ezseg.f -m ezsegwrapper -h ezseg.pyf creates ezseg.pyf file with ezsegwrapper function 2.) cp ezseg.pyf ezsegwrapper.pyf copy file and update to be python compatible 3.) python -m numpy.f2py -c ezsegwrapper.pyf ezseg.f creates shared module ezsegwrapper.so","title":"Fortran to Python"},{"location":"chd/f2py/#creating-wrapper-function-for-ezseg-algorithm","text":"How to create a wrapper function for Fortran code: more information can be found here 1.) python -m numpy.f2py ezseg.f -m ezsegwrapper -h ezseg.pyf creates ezseg.pyf file with ezsegwrapper function 2.) cp ezseg.pyf ezsegwrapper.pyf copy file and update to be python compatible 3.) python -m numpy.f2py -c ezsegwrapper.pyf ezseg.f creates shared module ezsegwrapper.so","title":"Creating Wrapper Function for Ezseg Algorithm"},{"location":"db/db/","text":"Database Information The Image Pre-Processing Pipeline is built upon a database to store images, histograms, and fit parameter values. Updating the Database The original database is now quite different than the database needed to query and save calculated parameters. In order to generate the necessary updates to run the code, do the following: 1.) install the python package Alembic in your python environment conda install -c conda-forge alembic additional installation information can be found here 2.) in the (CHD) project folder, run the script to update the database alembic upgrade head this will run the latest updates to the database 3.) to return to the original database, run the downgrade script alembic downgrade base this will return the database to it's original form 4.) to only run certain upgrades/downgrades run a specific number of revisions (n is the number of revisions to either upgrade/downgrade) alembic upgrade +n alembic downgrade -n run a specific upgrade/downgrade: scripts are found here alembic upgrade \"revision\" alembic downgrade \"revision\" \"revision\" refers to the first 3+ identifying characters from the specific script 5.) to create new update scripts alembic revision -m \"revision name\" edit this script with the upgrade/downgrade necessary Database Schema","title":"Database Basics"},{"location":"db/db/#database-information","text":"The Image Pre-Processing Pipeline is built upon a database to store images, histograms, and fit parameter values.","title":"Database Information"},{"location":"db/db/#updating-the-database","text":"The original database is now quite different than the database needed to query and save calculated parameters. In order to generate the necessary updates to run the code, do the following: 1.) install the python package Alembic in your python environment conda install -c conda-forge alembic additional installation information can be found here 2.) in the (CHD) project folder, run the script to update the database alembic upgrade head this will run the latest updates to the database 3.) to return to the original database, run the downgrade script alembic downgrade base this will return the database to it's original form 4.) to only run certain upgrades/downgrades run a specific number of revisions (n is the number of revisions to either upgrade/downgrade) alembic upgrade +n alembic downgrade -n run a specific upgrade/downgrade: scripts are found here alembic upgrade \"revision\" alembic downgrade \"revision\" \"revision\" refers to the first 3+ identifying characters from the specific script 5.) to create new update scripts alembic revision -m \"revision name\" edit this script with the upgrade/downgrade necessary","title":"Updating the Database"},{"location":"db/db/#database-schema","text":"","title":"Database Schema"},{"location":"db/iit/","text":"Database for Inter-Instrument Transformation For the Inter-Instrument Transformation, the database is used to query EUV Images and LBC Fit Parameters to apply the correction. 1D Intensity Histograms are created and stored in the database. After calculation, fit parameters are stored in the database then queried to apply the IIT Correction. Tables Histogram This table stores histogram and information associated with IIT Histograms. The histograms are created in Step One of Inter-Instrument Transformation Correction. Columns: hist_id: auto-incremented integer id associated with the histogram (Primary Key, Integer) image_id: integer id associated with image (Foreign Key: EUV Images, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) date_obs: time of image observation (DateTime) wavelength: observation wavelength (Integer) n_mu_bins: number of mu bins (Integer) n_intensity_bins: number of intensity bins (Integer) lat_band: latitude band (Blob) mu_bin_edges: array of mu bin edges from number of mu bins (Blob) intensity_bin_edges: array of intensity bin edges from number of intensity bins (Blob) hist: histogram associated with image (Blob) Image Combos This table stores information regarding the combination of images used to calculate the fit parameter. Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) n_images: number of images in combination (Integer) date_mean: mean date of images in image combination (DateTime) date_max: maximum date of images in image combination (DateTime) date_min: minimum date of images in image combination (DateTime) Image Combo Assoc This table stores specific image ids with the associated combo id. Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Foreign Key: Image Combos, Integer) image_id: integer id associated with image (Primary Key, Foreign Key: EUV Images, Integer) Method Defs This table stores information about a correction method and an associated integer method id. Columns: meth_id: auto-incremented integer id associated with the specific method (Primary Key, Integer) meth_name: method name (String) meth_description: description of method (String) Var Defs This table stores information about a variable and an associated integer variable id. Columns: var_id: auto-incremented integer id associated with the specific variable (Primary Key, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) var_name: variable name (String) var_description: description of variable (String) Var Vals This table stores variable values with the associated variable, method, and image combination. These values are calculated from the IIT fit analysis ( IIT Step Two ). These values are queried during the application of the correction ( IIT Step Three ) and during the creation of histogram plots ( IIT Step Four ). Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Foreign Key: Image Combos, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) var_id: auto-incremented integer id associated with the specific variable (Primary Key, Foreign Key: Var Defs, Integer) var_val: variable value (Float)","title":"Database for IIT"},{"location":"db/iit/#database-for-inter-instrument-transformation","text":"For the Inter-Instrument Transformation, the database is used to query EUV Images and LBC Fit Parameters to apply the correction. 1D Intensity Histograms are created and stored in the database. After calculation, fit parameters are stored in the database then queried to apply the IIT Correction.","title":"Database for Inter-Instrument Transformation"},{"location":"db/iit/#tables","text":"","title":"Tables"},{"location":"db/iit/#histogram","text":"This table stores histogram and information associated with IIT Histograms. The histograms are created in Step One of Inter-Instrument Transformation Correction. Columns: hist_id: auto-incremented integer id associated with the histogram (Primary Key, Integer) image_id: integer id associated with image (Foreign Key: EUV Images, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) date_obs: time of image observation (DateTime) wavelength: observation wavelength (Integer) n_mu_bins: number of mu bins (Integer) n_intensity_bins: number of intensity bins (Integer) lat_band: latitude band (Blob) mu_bin_edges: array of mu bin edges from number of mu bins (Blob) intensity_bin_edges: array of intensity bin edges from number of intensity bins (Blob) hist: histogram associated with image (Blob)","title":"Histogram"},{"location":"db/iit/#image-combos","text":"This table stores information regarding the combination of images used to calculate the fit parameter. Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) n_images: number of images in combination (Integer) date_mean: mean date of images in image combination (DateTime) date_max: maximum date of images in image combination (DateTime) date_min: minimum date of images in image combination (DateTime)","title":"Image Combos"},{"location":"db/iit/#image-combo-assoc","text":"This table stores specific image ids with the associated combo id. Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Foreign Key: Image Combos, Integer) image_id: integer id associated with image (Primary Key, Foreign Key: EUV Images, Integer)","title":"Image Combo Assoc"},{"location":"db/iit/#method-defs","text":"This table stores information about a correction method and an associated integer method id. Columns: meth_id: auto-incremented integer id associated with the specific method (Primary Key, Integer) meth_name: method name (String) meth_description: description of method (String)","title":"Method Defs"},{"location":"db/iit/#var-defs","text":"This table stores information about a variable and an associated integer variable id. Columns: var_id: auto-incremented integer id associated with the specific variable (Primary Key, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) var_name: variable name (String) var_description: description of variable (String)","title":"Var Defs"},{"location":"db/iit/#var-vals","text":"This table stores variable values with the associated variable, method, and image combination. These values are calculated from the IIT fit analysis ( IIT Step Two ). These values are queried during the application of the correction ( IIT Step Three ) and during the creation of histogram plots ( IIT Step Four ). Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Foreign Key: Image Combos, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) var_id: auto-incremented integer id associated with the specific variable (Primary Key, Foreign Key: Var Defs, Integer) var_val: variable value (Float)","title":"Var Vals"},{"location":"db/lbc/","text":"Database for Limb-Brightening Correction For the Limb-Brightening Correction, the database is used to query for images, store histograms, and store fit parameter values. These fit parameter values can then be queried in order to apply the Limb-Brightening correction. Tables EUV Images This table stores files and information associated with EUV Images. Columns: image_id: auto-incremented integer id associated with the image (Primary Key, Integer) date_obs: time of image observation (DateTime) instrument: observation instrument (String) wavelength: observation wavelength (Integer) fname_raw: associated fits file (String) fname_hdf: associated hdf5 file (String) distance: associated distance (Float) cr_lon: Carrington Longitude (Float) cr_lat: Carrington Latitude (Float) cr_rot: Carrington Rotation (Float) flag: default 0 (Integer) time_of_download: time of image download to database (DateTime) Histogram This table stores histogram and information associated with LBC Histograms. The histograms are created in Step One of Limb Brightening. Columns: hist_id: auto-incremented integer id associated with the histogram (Primary Key, Integer) image_id: integer id associated with image (Foreign Key: EUV Images, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) date_obs: time of image observation (DateTime) wavelength: observation wavelength (Integer) n_mu_bins: number of mu bins (Integer) n_intensity_bins: number of intensity bins (Integer) lat_band: latitude band (Blob) mu_bin_edges: array of mu bin edges from number of mu bins (Blob) intensity_bin_edges: array of intensity bin edges from number of intensity bins (Blob) hist: histogram associated with image (Blob) Image Combos This table stores information regarding the combination of images used to calculate the fit parameter. Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) n_images: number of images in combination (Integer) date_mean: mean date of images in image combination (DateTime) date_max: maximum date of images in image combination (DateTime) date_min: minimum date of images in image combination (DateTime) Image Combo Assoc This table stores specific image ids with the associated combo id. Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Foreign Key: Image Combos, Integer) image_id: integer id associated with image (Primary Key, Foreign Key: EUV Images, Integer) Method Defs This table stores information about a correction method and an associated integer method id. Columns: meth_id: auto-incremented integer id associated with the specific method (Primary Key, Integer) meth_name: method name (String) meth_description: description of method (String) Var Defs This table stores information about a variable and an associated integer variable id. Columns: var_id: auto-incremented integer id associated with the specific variable (Primary Key, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) var_name: variable name (String) var_description: description of variable (String) Var Vals This table stores variable values with the associated variable, method, and image combination. These values are calculated from the theoretical fit analysis ( LBC Step Two ). These values are queried during the application of the correction ( LBC Step Three ) and during the creation of beta and y plots ( LBC Step Four ). Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Foreign Key: Image Combos, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) var_id: auto-incremented integer id associated with the specific variable (Primary Key, Foreign Key: Var Defs, Integer) var_val: variable value (Float)","title":"Database for LBC"},{"location":"db/lbc/#database-for-limb-brightening-correction","text":"For the Limb-Brightening Correction, the database is used to query for images, store histograms, and store fit parameter values. These fit parameter values can then be queried in order to apply the Limb-Brightening correction.","title":"Database for Limb-Brightening Correction"},{"location":"db/lbc/#tables","text":"","title":"Tables"},{"location":"db/lbc/#euv-images","text":"This table stores files and information associated with EUV Images. Columns: image_id: auto-incremented integer id associated with the image (Primary Key, Integer) date_obs: time of image observation (DateTime) instrument: observation instrument (String) wavelength: observation wavelength (Integer) fname_raw: associated fits file (String) fname_hdf: associated hdf5 file (String) distance: associated distance (Float) cr_lon: Carrington Longitude (Float) cr_lat: Carrington Latitude (Float) cr_rot: Carrington Rotation (Float) flag: default 0 (Integer) time_of_download: time of image download to database (DateTime)","title":"EUV Images"},{"location":"db/lbc/#histogram","text":"This table stores histogram and information associated with LBC Histograms. The histograms are created in Step One of Limb Brightening. Columns: hist_id: auto-incremented integer id associated with the histogram (Primary Key, Integer) image_id: integer id associated with image (Foreign Key: EUV Images, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) date_obs: time of image observation (DateTime) wavelength: observation wavelength (Integer) n_mu_bins: number of mu bins (Integer) n_intensity_bins: number of intensity bins (Integer) lat_band: latitude band (Blob) mu_bin_edges: array of mu bin edges from number of mu bins (Blob) intensity_bin_edges: array of intensity bin edges from number of intensity bins (Blob) hist: histogram associated with image (Blob)","title":"Histogram"},{"location":"db/lbc/#image-combos","text":"This table stores information regarding the combination of images used to calculate the fit parameter. Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) n_images: number of images in combination (Integer) date_mean: mean date of images in image combination (DateTime) date_max: maximum date of images in image combination (DateTime) date_min: minimum date of images in image combination (DateTime)","title":"Image Combos"},{"location":"db/lbc/#image-combo-assoc","text":"This table stores specific image ids with the associated combo id. Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Foreign Key: Image Combos, Integer) image_id: integer id associated with image (Primary Key, Foreign Key: EUV Images, Integer)","title":"Image Combo Assoc"},{"location":"db/lbc/#method-defs","text":"This table stores information about a correction method and an associated integer method id. Columns: meth_id: auto-incremented integer id associated with the specific method (Primary Key, Integer) meth_name: method name (String) meth_description: description of method (String)","title":"Method Defs"},{"location":"db/lbc/#var-defs","text":"This table stores information about a variable and an associated integer variable id. Columns: var_id: auto-incremented integer id associated with the specific variable (Primary Key, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) var_name: variable name (String) var_description: description of variable (String)","title":"Var Defs"},{"location":"db/lbc/#var-vals","text":"This table stores variable values with the associated variable, method, and image combination. These values are calculated from the theoretical fit analysis ( LBC Step Two ). These values are queried during the application of the correction ( LBC Step Three ) and during the creation of beta and y plots ( LBC Step Four ). Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Foreign Key: Image Combos, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) var_id: auto-incremented integer id associated with the specific variable (Primary Key, Foreign Key: Var Defs, Integer) var_val: variable value (Float)","title":"Var Vals"},{"location":"db/map/","text":"Database for Coronal Hole Detection and Mapping For creation of EUV and CHD maps, the database is used to query EUV Images, LBC/IIT Correction Coefficients, and save mapping methods and resulting maps to the database. Tables EUV Images This table stores files and information associated with EUV Images. It is queried to get the original EUV Images before applying Image Pre-Processing (LBC and IIT) Corrections. Columns: image_id: auto-incremented integer id associated with the image (Primary Key, Integer) date_obs: time of image observation (DateTime) instrument: observation instrument (String) wavelength: observation wavelength (Integer) fname_raw: associated fits file (String) fname_hdf: associated hdf5 file (String) distance: associated distance (Float) cr_lon: Carrington Longitude (Float) cr_lat: Carrington Latitude (Float) cr_rot: Carrington Rotation (Float) flag: default 0 (Integer) time_of_download: time of image download to database (DateTime) Image Combos This table stores information regarding the combination of images used to calculate the fit parameter. It is used to determine what combo id corresponds to the date in question. Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) n_images: number of images in combination (Integer) date_mean: mean date of images in image combination (DateTime) date_max: maximum date of images in image combination (DateTime) date_min: minimum date of images in image combination (DateTime) Image Combo Assoc This table stores specific image ids with the associated combo id. It is used when querying for the correct combo id. Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Foreign Key: Image Combos, Integer) image_id: integer id associated with image (Primary Key, Foreign Key: EUV Images, Integer) Var Vals This table stores variable values with the associated variable, method, and image combination. It is queried for the correction parameters used for Limb-Brightening and Inter-Instrument Transformation corrections. Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Foreign Key: Image Combos, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) var_id: auto-incremented integer id associated with the specific variable (Primary Key, Foreign Key: Var Defs, Integer) var_val: variable value (Float) Method Defs This table stores information about a correction method and an associated integer method id, used when querying for correction parameters. Columns: meth_id: auto-incremented integer id associated with the specific method (Primary Key, Integer) meth_name: method name (String) meth_description: description of method (String) Var Defs This table stores information about a variable and an associated integer variable id. It is used when querying for correction parameters to apply LBC/IIT. Columns: var_id: auto-incremented integer id associated with the specific variable (Primary Key, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) var_name: variable name (String) var_description: description of variable (String) Var Vals Map This table stores variable values with the associated map, variable, method, and image combination. Values are saved here when the map is saved to the database. Columns: map_id: auto-incremented interger id associated with specific map (Primary Key, Integer) combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Foreign Key: Image Combos, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) var_id: auto-incremented integer id associated with the specific variable (Primary Key, Foreign Key: Var Defs, Integer) var_val: variable value (Float) Method Combos This table stores information about associated correction methods used in the creation of a map. A new method combination is created when a map is saved to the database. Columns: meth_combo_id: auto-incremented integer id associated with the specific method combination (Primary Key, Integer) n_methods: number of associated methods (Integer) Method Combo Assoc This table associates method combo ids with the method id. Columns: meth_combo_id: auto-incremented integer id associated with the specific method combination (Primary Key, Foreign Key: Method Combos, Integer) meth_id: auto-incremented integer id associated with the specific method (Primary Key, Foreign Key: Method Defs, Integer) EUV Maps This table stores files and information associated with EUV Maps. Columns: map_id: auto-incremented integer id associated with the map (Primary Key, Integer) combo_id: auto-incremented integer id associated with that specific combination of images (Foreign Key: Image Combos, Integer) meth_combo_id: auto-incremented integer id associated with the specific method combination (Primary Key, Foreign Key: Method Combos, Integer) fname: associated hdf5 file, saved either as a 'single' or 'synoptic' map (String) time_of_compute: time of map computation (DateTime)","title":"Database for CHD Mapping"},{"location":"db/map/#database-for-coronal-hole-detection-and-mapping","text":"For creation of EUV and CHD maps, the database is used to query EUV Images, LBC/IIT Correction Coefficients, and save mapping methods and resulting maps to the database.","title":"Database for Coronal Hole Detection and Mapping"},{"location":"db/map/#tables","text":"","title":"Tables"},{"location":"db/map/#euv-images","text":"This table stores files and information associated with EUV Images. It is queried to get the original EUV Images before applying Image Pre-Processing (LBC and IIT) Corrections. Columns: image_id: auto-incremented integer id associated with the image (Primary Key, Integer) date_obs: time of image observation (DateTime) instrument: observation instrument (String) wavelength: observation wavelength (Integer) fname_raw: associated fits file (String) fname_hdf: associated hdf5 file (String) distance: associated distance (Float) cr_lon: Carrington Longitude (Float) cr_lat: Carrington Latitude (Float) cr_rot: Carrington Rotation (Float) flag: default 0 (Integer) time_of_download: time of image download to database (DateTime)","title":"EUV Images"},{"location":"db/map/#image-combos","text":"This table stores information regarding the combination of images used to calculate the fit parameter. It is used to determine what combo id corresponds to the date in question. Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) n_images: number of images in combination (Integer) date_mean: mean date of images in image combination (DateTime) date_max: maximum date of images in image combination (DateTime) date_min: minimum date of images in image combination (DateTime)","title":"Image Combos"},{"location":"db/map/#image-combo-assoc","text":"This table stores specific image ids with the associated combo id. It is used when querying for the correct combo id. Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Foreign Key: Image Combos, Integer) image_id: integer id associated with image (Primary Key, Foreign Key: EUV Images, Integer)","title":"Image Combo Assoc"},{"location":"db/map/#var-vals","text":"This table stores variable values with the associated variable, method, and image combination. It is queried for the correction parameters used for Limb-Brightening and Inter-Instrument Transformation corrections. Columns: combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Foreign Key: Image Combos, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) var_id: auto-incremented integer id associated with the specific variable (Primary Key, Foreign Key: Var Defs, Integer) var_val: variable value (Float)","title":"Var Vals"},{"location":"db/map/#method-defs","text":"This table stores information about a correction method and an associated integer method id, used when querying for correction parameters. Columns: meth_id: auto-incremented integer id associated with the specific method (Primary Key, Integer) meth_name: method name (String) meth_description: description of method (String)","title":"Method Defs"},{"location":"db/map/#var-defs","text":"This table stores information about a variable and an associated integer variable id. It is used when querying for correction parameters to apply LBC/IIT. Columns: var_id: auto-incremented integer id associated with the specific variable (Primary Key, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) var_name: variable name (String) var_description: description of variable (String)","title":"Var Defs"},{"location":"db/map/#var-vals-map","text":"This table stores variable values with the associated map, variable, method, and image combination. Values are saved here when the map is saved to the database. Columns: map_id: auto-incremented interger id associated with specific map (Primary Key, Integer) combo_id: auto-incremented integer id associated with that specific combination of images (Primary Key, Foreign Key: Image Combos, Integer) meth_id: auto-incremented integer id associated with the specific method (Foreign Key: Method Defs, Integer) var_id: auto-incremented integer id associated with the specific variable (Primary Key, Foreign Key: Var Defs, Integer) var_val: variable value (Float)","title":"Var Vals Map"},{"location":"db/map/#method-combos","text":"This table stores information about associated correction methods used in the creation of a map. A new method combination is created when a map is saved to the database. Columns: meth_combo_id: auto-incremented integer id associated with the specific method combination (Primary Key, Integer) n_methods: number of associated methods (Integer)","title":"Method Combos"},{"location":"db/map/#method-combo-assoc","text":"This table associates method combo ids with the method id. Columns: meth_combo_id: auto-incremented integer id associated with the specific method combination (Primary Key, Foreign Key: Method Combos, Integer) meth_id: auto-incremented integer id associated with the specific method (Primary Key, Foreign Key: Method Defs, Integer)","title":"Method Combo Assoc"},{"location":"db/map/#euv-maps","text":"This table stores files and information associated with EUV Maps. Columns: map_id: auto-incremented integer id associated with the map (Primary Key, Integer) combo_id: auto-incremented integer id associated with that specific combination of images (Foreign Key: Image Combos, Integer) meth_combo_id: auto-incremented integer id associated with the specific method combination (Primary Key, Foreign Key: Method Combos, Integer) fname: associated hdf5 file, saved either as a 'single' or 'synoptic' map (String) time_of_compute: time of map computation (DateTime)","title":"EUV Maps"},{"location":"ipp/iit/","text":"Inter-Instrument Transformation The goal of the inter-instrument correction is to equate the intensities from one instrument to the intensities of another. The choice of which instrument to use as the \"reference instrument\" is an updatable parameter. Examples of Corrected Images These images of before and after applying IIT are from the different instruments at Carrington Rotation 2108.59. These can be enlarged by clicking image titles. AIA Images Original AIA Image Corrected AIA Image Difference AIA Image EUVI-A Images Original STA Image Corrected STA Image Difference STA Image EUVI-B Images Original STB Image Corrected STB Image Difference STB Image Examples of Histograms 200 Intensity Bin Histograms before and after IIT Correction. LBC Corrected Histogram IIT Corrected Histogram Analysis Pipeline Compute Histograms and Save to Database This function applies the limb-brightening correction, calculates the associated IIT histogram, and saves these histograms to the database. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 def create_histograms ( db_session , inst_list , lbc_query_time_min , lbc_query_time_max , hdf_data_dir , n_mu_bins = 18 , n_intensity_bins = 200 , lat_band = [ - np . pi / 64. , np . pi / 64. ], log10 = True , R0 = 1.01 ): \"\"\" function to apply LBC, create and save histograms to the database \"\"\" image_pd = db_funcs . query_euv_images ( db_session = db_session , time_min = lbc_query_time_min , time_max = lbc_query_time_max , instrument = query_instrument ) combo_query = db_funcs . query_inst_combo ( db_session , lbc_query_time_min , lbc_query_time_max , meth_name = \"LBCC Theoretic\" , instrument = instrument ) original_los , lbcc_image , mu_indices , use_indices , theoretic_query = lbcc_funcs . apply_lbc ( db_session , hdf_data_dir , combo_query , image_row = row , n_intensity_bins = n_intensity_bins , R0 = R0 ) hist = psi_d_types . LBCCImage . iit_hist ( lbcc_image , lat_band , log10 ) iit_hist = psi_d_types . create_iit_hist ( lbcc_image , method_id [ 1 ], lat_band , hist ) db_funcs . add_hist ( db_session , iit_hist ) 1.) db_funcs.query_euv_images queries database for images (from EUV_Images table) in specified date range 2.) db_funcs.query_inst_combo queries database for closest image combinations to date observed 3.) lbcc_funcs.apply_lbc applies Limb-Brightening Correction to images and creates LBCCImage datatype 4.) psi_d_types.LBCCImage.iit_hist calculates IIT histogram from LBC corrected data 5.) psi_d_types.create_iit_hist creates IIT histogram datatype 6.) db_funcs.add_hist saves histograms to database (table Histogram) associating an image_id, meth_id, and basic information with histogram Calculate and Save Correction Coefficients This function queries the database for IIT histograms, calculates correction coefficients, and saves them to the database. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 def calc_iit_coefficients ( db_session , inst_list , ref_inst , calc_query_time_min , calc_query_time_max , weekday = 0 , number_of_days = 180 , n_intensity_bins = 200 , lat_band = [ - np . pi / 2.4 , np . pi / 2.4 ], create = False ): \"\"\" function to query IIT histograms, calculate IIT coefficients, and save to database \"\"\" euv_images = db_funcs . query_euv_images ( db_session , time_min = calc_query_time_min , time_max = calc_query_time_max , instrument = ref_instrument ) ref_hist_pd = db_funcs . query_hist ( db_session = db_session , meth_id = method_id [ 1 ], n_intensity_bins = n_intensity_bins , lat_band = np . array ( lat_band ) . tobytes (), time_min = calc_query_time_min - datetime . timedelta ( days = number_of_days ), time_max = calc_query_time_max + datetime . timedelta ( days = number_of_days ), instrument = ref_instrument ) rot_images = db_funcs . query_euv_images_rot ( db_session , rot_min = rot_min , rot_max = rot_max , instrument = query_instrument ) alpha_x_parameters = iit . optim_iit_linear ( norm_hist_ref , norm_hist_fit , intensity_bin_edges , init_pars = init_pars ) db_funcs . store_iit_values ( db_session , pd_hist , meth_name , meth_desc , alpha_x_parameters . x , create ) 1.) db_funcs.query_euv_images queries database for euv images for the reference instrument used to get a range of Carrington rotation for which to calculate fit coefficients 2.) db_funcs.query_hist queries database for histograms (from Histogram table) in specified date range 3.) db_funcs.query_euv_images_rot queries database for euv images by Carrington rotation range 4.) iit.optim_iit_linear use linear optimization method to calculate fit parameters hist_ref and hist_fit are the reference histogram and the instrument histogram for the fit these are determined using boolean indexing 5.) db_funcs.store_iit_values save the two fit coefficients to database using function store_iit_values creates image combination combo_id of image_ids and dates in Images_Combos table creates association between each image_id and combo_id in Image_Combo_Assoc table creates new method \u201cIIT\u201d with an associated meth_id in Meth_Defs table creates new variable definitions \"alpha and \"x\"\" with an associated var_id in Var_Defs table store variable value as float in Var_Vals table with associated combo_id, meth_id, and var_id Apply Inter-Instrument Transformation and Plot New Images This function queries the database for IIT coefficients, applies the correction, and plots resulting images. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def apply_iit_correction ( db_session , hdf_data_dir , iit_query_time_min , iit_query_time_max , inst_list , n_mu_bins , n_intensity_bins , n_images_plot = 1 , plot = False ): \"\"\" function to query IIT correction coefficients, apply correction, and plot resulting images \"\"\" euv_images = db_funcs . query_euv_images ( db_session , time_min = iit_query_time_min , time_max = iit_query_time_max , instrument = ref_instrument ) rot_images = db_funcs . query_euv_images_rot ( db_session , rot_min = rot_min , rot_max = rot_max , instrument = query_instrument ) combo_query_lbc = db_funcs . query_inst_combo ( db_session , iit_query_time_min , iit_query_time_max , lbc_meth_name , instrument ) combo_query_iit = db_funcs . query_inst_combo ( db_session , iit_query_time_min , iit_query_time_max , iit_meth_name , instrument ) original_los , lbcc_image , mu_indices , use_indices , theoretic_query = lbcc_funcs . apply_lbc ( db_session , hdf_data_dir , combo_query_lbc , image_row = row , n_intensity_bins = n_intensity_bins , R0 = R0 ) lbcc_image , iit_image , use_indices , alpha , x = apply_iit ( db_session , hdf_data_dir , combo_query_iit , lbcc_image , use_indices , image_row = row , R0 = R0 ) if plot : Plotting . PlotCorrectedImage ( lbcc_data , los_image = original_los , nfig = 100 + inst_index * 10 + index , title = \"Corrected LBCC Image for \" + instrument ) Plotting . PlotCorrectedImage ( corrected_iit_data , los_image = original_los , nfig = 200 + inst_index * 10 + index , title = \"Corrected IIT Image for \" + instrument ) Plotting . PlotCorrectedImage ( lbcc_data - corrected_iit_data , los_image = original_los , nfig = 300 + inst_index * 10 + index , title = \"Difference Plot for \" + instrument ) 1.) db_funcs.query_euv_images queries database for images (from EUV_Images table) in specified date range queries for reference instrument to get minimum and maximum Carrington rotation 2.) db_funcs.query_euv_images_rot queries for instrument in question based on Carrington rotation range 3.) db_funcs.query_inst_combo queries database for closest image combinations to date observed does this for both the LBC and IIT methods 4.) lbcc_funcs.apply_lbc applies Limb-Brightening Correction to images and creates LBCCImage datatype 5.) apply_iit applies Inter-Instrument Transformation Correction to images and creates IITImage datatype 6.) Plotting.PlotCorrectedImage plots LBC images, IIT corrected images, and the difference between them Apply IIT This is a sub-step that applies the Inter-Instrument Transformation Correction to individual image and returns the correct IIT Image. It is called during the third step of Inter-Instrument Transformation. 1 2 3 4 5 6 7 8 9 10 11 12 13 def apply_iit ( db_session , hdf_data_dir , inst_combo_query , lbcc_image , image_row , R0 = 1.01 ): \"\"\" function to apply IIT to a specific image, returns corrected image \"\"\" method_id_info = db_funcs . get_method_id ( db_session , meth_name , meth_desc = None , var_names = None , var_descs = None , create = False ) alpha_x_parameters = db_funcs . query_var_val ( db_session , meth_name , date_obs = lbcc_image . date_obs , inst_combo_query = inst_combo_query ) corrected_iit_data [ use_indices ] = 10 ** ( alpha * np . log10 ( lbcc_data [ use_indices ]) + x ) iit_image = psi_d_types . create_iit_image ( lbcc_image , corrected_iit_data , method_id_info [ 1 ], hdf_path ) return lbcc_image , iit_image , use_indices , alpha , x 1.) db_funcs.get_method_id queries database for method id associated with method name 2.) db_funcs.query_var_val queries database for variable values associated with specific image (from Var_Vals table) 3.) corrected_iit_data[use_indices] = 10 ** (alpha * np.log10(lbcc_data[use_indices]) + x) applies correction to image based off alpha, x, and lbcc corrected data arrays 4.) psi_d_types.create_iit_image create IIT Image datatype from corrected IIT data Generate Histogram Plots This function generates histogram plots comparing data from before and after the IIT correction. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def plot_iit_histograms ( db_session , hdf_data_dir , hist_query_time_min , hist_query_time_max , inst_list , ref_inst , n_intensity_bins = 200 , lat_band = [ - np . pi / 2.4 , np . pi / 2.4 ], R0 = 1.01 , log10 = True ): \"\"\" function to create corrected IIT histograms then plot original, LBC Corrected, and IIT Corrected histograms for comparison \"\"\" pd_hist = db_funcs . query_hist ( db_session = db_session , meth_id = method_id [ 1 ], n_intensity_bins = n_intensity_bins , lat_band = np . array ( lat_band ) . tobytes (), time_min = hist_query_time_min , time_max = hist_query_time_max ) combo_query_lbc = db_funcs . query_inst_combo ( db_session , hist_query_time_min , hist_query_time_max , meth_name = \"LBCC Theoretic\" , instrument = instrument ) combo_query_iit = db_funcs . query_inst_combo ( db_session , hist_query_time_min , hist_query_time_max , meth_name = \"IIT\" , instrument = instrument ) image_pd = db_funcs . query_euv_images ( db_session = db_session , time_min = hist_query_time_min , time_max = hist_query_time_max , instrument = query_instrument ) original_los , lbcc_image , mu_indices , use_indices , theoretic_query = lbcc_funcs . apply_lbc ( db_session , hdf_data_dir , combo_query_lbc , image_row = row , n_intensity_bins = n_intensity_bins , R0 = R0 ) original_los_hist = psi_d_types . LosImage . iit_hist ( original_los , intensity_bin_edges , lat_band , log10 ) lbcc_image , iit_image , use_indices , alpha , x = apply_iit ( db_session , hdf_data_dir , combo_query_iit , lbcc_image , use_indices , image_row = row , R0 = R0 ) hist_iit = psi_d_types . IITImage . iit_hist ( iit_image , lat_band , log10 ) Plotting . Plot1d_Hist ( norm_original_hist , instrument , inst_index , intensity_bin_edges , color_list , linestyle_list , figure = 100 , xlabel = \"Intensity (log10)\" , ylabel = \"H(I)\" , title = \"Histogram: Original Image\" ) Plotting . Plot1d_Hist ( norm_lbc_hist , instrument , inst_index , intensity_bin_edges , color_list , linestyle_list , figure = 200 , xlabel = \"Intensity (log10)\" , ylabel = \"H(I)\" , title = \"Histogram: Post LBCC\" ) Plotting . Plot1d_Hist ( norm_corrected_hist , instrument , inst_index , intensity_bin_edges , color_list , linestyle_list , figure = 300 , xlabel = \"Intensity (log10)\" , ylabel = \"H(I)\" , title = \"Histogram: Post IIT\" ) 1.) db_funcs.query_hist queries database for histograms (from Histogram table) in specified date range 2.) db_funcs.query_euv_images queries database for images (from EUV_Images table) in specified date range 3.) db_funcs.query_inst_combo queries database for closest image combinations to date observed does this for both the LBC and IIT methods 3.) lbcc_funcs.apply_lbc applies Limb-Brightening Correction to images and creates LBCCImage datatype 4.) psi_d_types.LosImage.iit_hist create 1D IIT Histogram from original LOS image data 5.) apply_iit applies Inter-Instrument Transformation Correction to images and creates IITImage datatype 6.) psi_d_types.IITImage.iit_hist create 1D IIT Histogram from corrected IIT image data 7.) Plotting.Plot1d_Hist plot 1D Normalized IIT Histograms for original, LBC, and IIT data","title":"Inter-Instrument Transformation"},{"location":"ipp/iit/#inter-instrument-transformation","text":"The goal of the inter-instrument correction is to equate the intensities from one instrument to the intensities of another. The choice of which instrument to use as the \"reference instrument\" is an updatable parameter.","title":"Inter-Instrument Transformation"},{"location":"ipp/iit/#examples-of-corrected-images","text":"These images of before and after applying IIT are from the different instruments at Carrington Rotation 2108.59. These can be enlarged by clicking image titles.","title":"Examples of Corrected Images"},{"location":"ipp/iit/#aia-images","text":"Original AIA Image Corrected AIA Image Difference AIA Image","title":"AIA Images"},{"location":"ipp/iit/#euvi-a-images","text":"Original STA Image Corrected STA Image Difference STA Image","title":"EUVI-A Images"},{"location":"ipp/iit/#euvi-b-images","text":"Original STB Image Corrected STB Image Difference STB Image","title":"EUVI-B Images"},{"location":"ipp/iit/#examples-of-histograms","text":"200 Intensity Bin Histograms before and after IIT Correction. LBC Corrected Histogram IIT Corrected Histogram","title":"Examples of Histograms"},{"location":"ipp/iit/#analysis-pipeline","text":"","title":"Analysis Pipeline"},{"location":"ipp/iit/#compute-histograms-and-save-to-database","text":"This function applies the limb-brightening correction, calculates the associated IIT histogram, and saves these histograms to the database. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 def create_histograms ( db_session , inst_list , lbc_query_time_min , lbc_query_time_max , hdf_data_dir , n_mu_bins = 18 , n_intensity_bins = 200 , lat_band = [ - np . pi / 64. , np . pi / 64. ], log10 = True , R0 = 1.01 ): \"\"\" function to apply LBC, create and save histograms to the database \"\"\" image_pd = db_funcs . query_euv_images ( db_session = db_session , time_min = lbc_query_time_min , time_max = lbc_query_time_max , instrument = query_instrument ) combo_query = db_funcs . query_inst_combo ( db_session , lbc_query_time_min , lbc_query_time_max , meth_name = \"LBCC Theoretic\" , instrument = instrument ) original_los , lbcc_image , mu_indices , use_indices , theoretic_query = lbcc_funcs . apply_lbc ( db_session , hdf_data_dir , combo_query , image_row = row , n_intensity_bins = n_intensity_bins , R0 = R0 ) hist = psi_d_types . LBCCImage . iit_hist ( lbcc_image , lat_band , log10 ) iit_hist = psi_d_types . create_iit_hist ( lbcc_image , method_id [ 1 ], lat_band , hist ) db_funcs . add_hist ( db_session , iit_hist ) 1.) db_funcs.query_euv_images queries database for images (from EUV_Images table) in specified date range 2.) db_funcs.query_inst_combo queries database for closest image combinations to date observed 3.) lbcc_funcs.apply_lbc applies Limb-Brightening Correction to images and creates LBCCImage datatype 4.) psi_d_types.LBCCImage.iit_hist calculates IIT histogram from LBC corrected data 5.) psi_d_types.create_iit_hist creates IIT histogram datatype 6.) db_funcs.add_hist saves histograms to database (table Histogram) associating an image_id, meth_id, and basic information with histogram","title":"Compute Histograms and Save to Database"},{"location":"ipp/iit/#calculate-and-save-correction-coefficients","text":"This function queries the database for IIT histograms, calculates correction coefficients, and saves them to the database. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 def calc_iit_coefficients ( db_session , inst_list , ref_inst , calc_query_time_min , calc_query_time_max , weekday = 0 , number_of_days = 180 , n_intensity_bins = 200 , lat_band = [ - np . pi / 2.4 , np . pi / 2.4 ], create = False ): \"\"\" function to query IIT histograms, calculate IIT coefficients, and save to database \"\"\" euv_images = db_funcs . query_euv_images ( db_session , time_min = calc_query_time_min , time_max = calc_query_time_max , instrument = ref_instrument ) ref_hist_pd = db_funcs . query_hist ( db_session = db_session , meth_id = method_id [ 1 ], n_intensity_bins = n_intensity_bins , lat_band = np . array ( lat_band ) . tobytes (), time_min = calc_query_time_min - datetime . timedelta ( days = number_of_days ), time_max = calc_query_time_max + datetime . timedelta ( days = number_of_days ), instrument = ref_instrument ) rot_images = db_funcs . query_euv_images_rot ( db_session , rot_min = rot_min , rot_max = rot_max , instrument = query_instrument ) alpha_x_parameters = iit . optim_iit_linear ( norm_hist_ref , norm_hist_fit , intensity_bin_edges , init_pars = init_pars ) db_funcs . store_iit_values ( db_session , pd_hist , meth_name , meth_desc , alpha_x_parameters . x , create ) 1.) db_funcs.query_euv_images queries database for euv images for the reference instrument used to get a range of Carrington rotation for which to calculate fit coefficients 2.) db_funcs.query_hist queries database for histograms (from Histogram table) in specified date range 3.) db_funcs.query_euv_images_rot queries database for euv images by Carrington rotation range 4.) iit.optim_iit_linear use linear optimization method to calculate fit parameters hist_ref and hist_fit are the reference histogram and the instrument histogram for the fit these are determined using boolean indexing 5.) db_funcs.store_iit_values save the two fit coefficients to database using function store_iit_values creates image combination combo_id of image_ids and dates in Images_Combos table creates association between each image_id and combo_id in Image_Combo_Assoc table creates new method \u201cIIT\u201d with an associated meth_id in Meth_Defs table creates new variable definitions \"alpha and \"x\"\" with an associated var_id in Var_Defs table store variable value as float in Var_Vals table with associated combo_id, meth_id, and var_id","title":"Calculate and Save Correction Coefficients"},{"location":"ipp/iit/#apply-inter-instrument-transformation-and-plot-new-images","text":"This function queries the database for IIT coefficients, applies the correction, and plots resulting images. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def apply_iit_correction ( db_session , hdf_data_dir , iit_query_time_min , iit_query_time_max , inst_list , n_mu_bins , n_intensity_bins , n_images_plot = 1 , plot = False ): \"\"\" function to query IIT correction coefficients, apply correction, and plot resulting images \"\"\" euv_images = db_funcs . query_euv_images ( db_session , time_min = iit_query_time_min , time_max = iit_query_time_max , instrument = ref_instrument ) rot_images = db_funcs . query_euv_images_rot ( db_session , rot_min = rot_min , rot_max = rot_max , instrument = query_instrument ) combo_query_lbc = db_funcs . query_inst_combo ( db_session , iit_query_time_min , iit_query_time_max , lbc_meth_name , instrument ) combo_query_iit = db_funcs . query_inst_combo ( db_session , iit_query_time_min , iit_query_time_max , iit_meth_name , instrument ) original_los , lbcc_image , mu_indices , use_indices , theoretic_query = lbcc_funcs . apply_lbc ( db_session , hdf_data_dir , combo_query_lbc , image_row = row , n_intensity_bins = n_intensity_bins , R0 = R0 ) lbcc_image , iit_image , use_indices , alpha , x = apply_iit ( db_session , hdf_data_dir , combo_query_iit , lbcc_image , use_indices , image_row = row , R0 = R0 ) if plot : Plotting . PlotCorrectedImage ( lbcc_data , los_image = original_los , nfig = 100 + inst_index * 10 + index , title = \"Corrected LBCC Image for \" + instrument ) Plotting . PlotCorrectedImage ( corrected_iit_data , los_image = original_los , nfig = 200 + inst_index * 10 + index , title = \"Corrected IIT Image for \" + instrument ) Plotting . PlotCorrectedImage ( lbcc_data - corrected_iit_data , los_image = original_los , nfig = 300 + inst_index * 10 + index , title = \"Difference Plot for \" + instrument ) 1.) db_funcs.query_euv_images queries database for images (from EUV_Images table) in specified date range queries for reference instrument to get minimum and maximum Carrington rotation 2.) db_funcs.query_euv_images_rot queries for instrument in question based on Carrington rotation range 3.) db_funcs.query_inst_combo queries database for closest image combinations to date observed does this for both the LBC and IIT methods 4.) lbcc_funcs.apply_lbc applies Limb-Brightening Correction to images and creates LBCCImage datatype 5.) apply_iit applies Inter-Instrument Transformation Correction to images and creates IITImage datatype 6.) Plotting.PlotCorrectedImage plots LBC images, IIT corrected images, and the difference between them","title":"Apply Inter-Instrument Transformation and Plot New Images"},{"location":"ipp/iit/#apply-iit","text":"This is a sub-step that applies the Inter-Instrument Transformation Correction to individual image and returns the correct IIT Image. It is called during the third step of Inter-Instrument Transformation. 1 2 3 4 5 6 7 8 9 10 11 12 13 def apply_iit ( db_session , hdf_data_dir , inst_combo_query , lbcc_image , image_row , R0 = 1.01 ): \"\"\" function to apply IIT to a specific image, returns corrected image \"\"\" method_id_info = db_funcs . get_method_id ( db_session , meth_name , meth_desc = None , var_names = None , var_descs = None , create = False ) alpha_x_parameters = db_funcs . query_var_val ( db_session , meth_name , date_obs = lbcc_image . date_obs , inst_combo_query = inst_combo_query ) corrected_iit_data [ use_indices ] = 10 ** ( alpha * np . log10 ( lbcc_data [ use_indices ]) + x ) iit_image = psi_d_types . create_iit_image ( lbcc_image , corrected_iit_data , method_id_info [ 1 ], hdf_path ) return lbcc_image , iit_image , use_indices , alpha , x 1.) db_funcs.get_method_id queries database for method id associated with method name 2.) db_funcs.query_var_val queries database for variable values associated with specific image (from Var_Vals table) 3.) corrected_iit_data[use_indices] = 10 ** (alpha * np.log10(lbcc_data[use_indices]) + x) applies correction to image based off alpha, x, and lbcc corrected data arrays 4.) psi_d_types.create_iit_image create IIT Image datatype from corrected IIT data","title":"Apply IIT"},{"location":"ipp/iit/#generate-histogram-plots","text":"This function generates histogram plots comparing data from before and after the IIT correction. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def plot_iit_histograms ( db_session , hdf_data_dir , hist_query_time_min , hist_query_time_max , inst_list , ref_inst , n_intensity_bins = 200 , lat_band = [ - np . pi / 2.4 , np . pi / 2.4 ], R0 = 1.01 , log10 = True ): \"\"\" function to create corrected IIT histograms then plot original, LBC Corrected, and IIT Corrected histograms for comparison \"\"\" pd_hist = db_funcs . query_hist ( db_session = db_session , meth_id = method_id [ 1 ], n_intensity_bins = n_intensity_bins , lat_band = np . array ( lat_band ) . tobytes (), time_min = hist_query_time_min , time_max = hist_query_time_max ) combo_query_lbc = db_funcs . query_inst_combo ( db_session , hist_query_time_min , hist_query_time_max , meth_name = \"LBCC Theoretic\" , instrument = instrument ) combo_query_iit = db_funcs . query_inst_combo ( db_session , hist_query_time_min , hist_query_time_max , meth_name = \"IIT\" , instrument = instrument ) image_pd = db_funcs . query_euv_images ( db_session = db_session , time_min = hist_query_time_min , time_max = hist_query_time_max , instrument = query_instrument ) original_los , lbcc_image , mu_indices , use_indices , theoretic_query = lbcc_funcs . apply_lbc ( db_session , hdf_data_dir , combo_query_lbc , image_row = row , n_intensity_bins = n_intensity_bins , R0 = R0 ) original_los_hist = psi_d_types . LosImage . iit_hist ( original_los , intensity_bin_edges , lat_band , log10 ) lbcc_image , iit_image , use_indices , alpha , x = apply_iit ( db_session , hdf_data_dir , combo_query_iit , lbcc_image , use_indices , image_row = row , R0 = R0 ) hist_iit = psi_d_types . IITImage . iit_hist ( iit_image , lat_band , log10 ) Plotting . Plot1d_Hist ( norm_original_hist , instrument , inst_index , intensity_bin_edges , color_list , linestyle_list , figure = 100 , xlabel = \"Intensity (log10)\" , ylabel = \"H(I)\" , title = \"Histogram: Original Image\" ) Plotting . Plot1d_Hist ( norm_lbc_hist , instrument , inst_index , intensity_bin_edges , color_list , linestyle_list , figure = 200 , xlabel = \"Intensity (log10)\" , ylabel = \"H(I)\" , title = \"Histogram: Post LBCC\" ) Plotting . Plot1d_Hist ( norm_corrected_hist , instrument , inst_index , intensity_bin_edges , color_list , linestyle_list , figure = 300 , xlabel = \"Intensity (log10)\" , ylabel = \"H(I)\" , title = \"Histogram: Post IIT\" ) 1.) db_funcs.query_hist queries database for histograms (from Histogram table) in specified date range 2.) db_funcs.query_euv_images queries database for images (from EUV_Images table) in specified date range 3.) db_funcs.query_inst_combo queries database for closest image combinations to date observed does this for both the LBC and IIT methods 3.) lbcc_funcs.apply_lbc applies Limb-Brightening Correction to images and creates LBCCImage datatype 4.) psi_d_types.LosImage.iit_hist create 1D IIT Histogram from original LOS image data 5.) apply_iit applies Inter-Instrument Transformation Correction to images and creates IITImage datatype 6.) psi_d_types.IITImage.iit_hist create 1D IIT Histogram from corrected IIT image data 7.) Plotting.Plot1d_Hist plot 1D Normalized IIT Histograms for original, LBC, and IIT data","title":"Generate Histogram Plots"},{"location":"ipp/lbc/","text":"Limb-Brightening Correction Limb Brightening Correction (LBC) is the second step in the data pre-processing pipeline. The goal of LBC is to correct for brightening of structures that is dependent upon their distance from disk center. Examples of Corrected Images These images of before and after applying LBC are from the different instruments on April 1, 2011. These can be enlarged by clicking image titles. AIA Images Original AIA Image Corrected AIA Image Difference AIA Image EUVI-A Images Original STA Image Corrected STA Image Difference STA Image EUVI-B Images Original STB Image Corrected STB Image Difference STB Image Theoretical Analysis Pipeline Compute Histograms and Save to Database This function computes 2D Histograms from processed images for use in the LBC process. It then saves these computed histograms to the database. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 def save_histograms ( db_session , hdf_data_dir , inst_list , hist_query_time_min , hist_query_time_max , n_mu_bins = 18 , n_intensity_bins = 200 , lat_band = [ - np . pi / 64. , np . pi / 64. ], log10 = True , R0 = 1.01 ): \"\"\" function to create and save histograms to database \"\"\" query_pd = db_funcs . query_euv_images ( db_session = db_session , time_min = hist_query_time_min , time_max = hist_query_time_max , instrument = query_instrument ) temp_hist = los_temp . mu_hist ( image_intensity_bin_edges , mu_bin_edges , lat_band = lat_band , log10 = log10 ) hist_lbcc = psi_d_types . create_lbcc_hist ( hdf_path , row . image_id , method_id [ 1 ], mu_bin_edges , image_intensity_bin_edges , lat_band , temp_hist ) db_funcs . add_hist ( db_session , hist_lbcc ) 1.) db_funcs.query_euv_images queries database for images (from EUV_Images table) in specified date range 2.) los_temp.mu_hist creates histogram based on number of mu and intensity bins 3.) psi_d_types.create_lbcc_hist create histogram datatype from lbcc histogram 4.) db_funcs.add_hist saves histograms to database (table Histogram) associating an image_id, meth_id, and basic information with histogram Calculate and Save Theoretical Fit Parameters This function queries histograms from the database then calculates LBC fit parameters which are then saved in the database. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def calc_theoretic_fit ( db_session , inst_list , calc_query_time_min , calc_query_time_max , weekday = 0 , number_of_days = 180 , n_mu_bins = 18 , n_intensity_bins = 200 , lat_band = [ - np . pi / 64. , np . pi / 64. ], create = False ): \"\"\" function to calculate and save (to database) theoretic LBC fit parameters \"\"\" pd_hist = db_funcs . query_hist ( db_session = db_session , meth_id = method_id [ 1 ], n_mu_bins = n_mu_bins , n_intensity_bins = n_intensity_bins , lat_band = np . array ( lat_band ) . tobytes (), time_min = np . datetime64 ( min_date ) . astype ( datetime . datetime ), time_max = np . datetime64 ( max_date ) . astype ( datetime . datetime ), instrument = query_instrument ) optim_out_theo = optim . minimize ( lbcc . get_functional_sse , init_pars , args = ( hist_ref , hist_mat , mu_vec , intensity_bin_array , model ), method = \"BFGS\" ) db_funcs . store_lbcc_values ( db_session , pd_hist , meth_name , meth_desc , var_name , var_desc , date_index , inst_index , optim_vals = optim_vals_theo [ 0 : 6 ], results = results_theo , create = True ) 1.) db_funcs.query_hist queries database for histograms (from Histogram table) in specified date range 2.) optim.minimize use theoretical optimization method to calculate fit parameters 3.) db_funcs.store_lbcc_values save the six fit parameters to database using function store_lbcc_values creates image combination combo_id of image_ids and dates in Images_Combos table creates association between each image_id and combo_id in Image_Combo_Assoc table creates new method \u201cLBCC Theoretic\u201d with an associated meth_id in Meth_Defs table creates new variable definitions \u201cTheoVar\u201d + index with an associated var_id in Var_Defs table store variable value as float in Var_Vals table with associated combo_id, meth_id, and var_id Apply Limb-Brightening Correction and Plot Corrected Images This function queries the database for LBC fit parameters then applies them to specified images, plotting resulting images before and after the correction. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def apply_lbc_correction ( db_session , hdf_data_dir , inst_list , lbc_query_time_min , lbc_query_time_max , n_intensity_bins = 200 , R0 = 1.01 , n_images_plot = 1 , plot = False ): \"\"\" function to apply limb-brightening correction and plot images within a certain time frame \"\"\" image_pd = db_funcs . query_euv_images ( db_session = db_session , time_min = lbc_query_time_min , time_max = lbc_query_time_max , instrument = query_instrument ) combo_query = db_funcs . query_inst_combo ( db_session , lbc_query_time_min , lbc_query_time_max , meth_name , instrument ) original_los , lbcc_image , mu_indices , use_indices = apply_lbc ( db_session , hdf_data_dir , combo_query , image_row = row , n_intensity_bins = n_intensity_bins , R0 = R0 ) if plot : Plotting . PlotImage ( original_los , nfig = 100 + inst_index * 10 + index , title = \"Original LOS Image for \" + instrument ) Plotting . PlotCorrectedImage ( corrected_data = lbcc_image . lbcc_data , los_image = original_los , nfig = 200 + inst_index * 10 + index , title = \"Corrected LBCC Image for \" + instrument ) Plotting . PlotCorrectedImage ( corrected_data = original_los . data - lbcc_image . lbcc_data , los_image = original_los , nfig = 300 + inst_index * 10 + index , title = \"Difference Plot for \" + instrument ) 1.) db_funcs.query_euv_images queries database for images (from EUV_Images table) in specified date range 2.) db_funcs.query_inst_combo queries database for closest image combinations to date observed 3.) db_funcs.query_var_val queries database for variable values associated with specific image (from Var_Vals table) 4.) lbcc.get_beta_y_theoretic_continuous_1d_indices calculates 1d beta and y arrays for valid mu indices uses variable values from query in step two uses original los image to determine indices for correction 5.) corrected_lbc_data[use_indices] = 10 ** (beta1d * np.log10(original_los.data[use_indices]) + y1d) applies correction to image based off beta, y, and original data arrays 6.) Plotting.PlotImage and Plotting.PlotCorrectedImage plots original and corrected images, and difference between them Apply LBC This is a sub-step that applies the Limb-Brightening Corrrection to individual image and returns the correct LBCC Image. It is called during the third step of Limb-Brightening. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def apply_lbc ( db_session , hdf_data_dir , inst_combo_query , image_row , n_intensity_bins = 200 , R0 = 1.01 ): \"\"\" function to apply LBC to a specific image, returns corrected image \"\"\" db_sesh , meth_id , var_ids = db_funcs . get_method_id ( db_session , meth_name , meth_desc = None , var_names = None , var_descs = None , create = False ) original_los = psi_d_types . read_los_image ( hdf_path ) theoretic_query = db_funcs . query_var_val ( db_session , meth_name , date_obs = original_los . info [ 'date_string' ], inst_combo_query = inst_combo_query ) beta1d , y1d , mu_indices , use_indices = lbcc . get_beta_y_theoretic_continuous_1d_indices ( theoretic_query , los_image = original_los ) corrected_lbc_data [ use_indices ] = 10 ** ( beta1d * np . log10 ( original_los . data [ use_indices ]) + y1d ) lbcc_image = psi_d_types . create_lbcc_image ( hdf_path , corrected_lbc_data , image_id = image_row . image_id , meth_id = meth_id , intensity_bin_edges = intensity_bin_edges ) return original_los , lbcc_image , mu_indices , use_indices , theoretic_query 1.) db_funcs.get_method_id queries database for method id associated with method name 2.) psi_d_types.read_los_image reads in los image from database 3.) db_funcs.query_var_val queries database for variable values associated with specific image (from Var_Vals table) 4.) lbcc.get_beta_y_theoretic_continuous_1d_indices calculates 1d beta and y arrays for valid mu indices uses variable values from query in step two uses original los image to determine indices for correction 5.) corrected_lbc_data[use_indices] = 10 ** (beta1d * np.log10(original_los.data[use_indices]) + y1d) applies correction to image based off beta, y, and original data arrays 6.) psi_d_types.create_lbcc_image create LBCC Image datatype from corrected LBC data Generate Plots of Beta and y This function queries the database for LBC fit parameters then generates plots of Beta and y over time. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 def generate_theoretic_plots ( db_session , inst_list , plot_query_time_min , plot_query_time_max , weekday , image_out_path , year = '2011' , time_period = '6 Month' , plot_week = 0 , n_mu_bins = 18 ): \"\"\" function to generate plots of beta/y over time and beta/y v. mu \"\"\" combo_query = db_funcs . query_inst_combo ( db_session , plot_query_time_min , plot_query_time_max , meth_name , instrument ) theoretic_query [ date_index , :] = db_funcs . query_var_val ( db_session , meth_name , date_obs = np . datetime64 ( center_date ) . astype ( datetime . datetime ), inst_combo_query = inst_combo_query ) plot_beta [ mu_index , date_index ], plot_y [ mu_index , date_index ] = lbcc . get_beta_y_theoretic_based ( theoretic_query [ date_index , :], mu ) beta_y_v_mu [ index , :] = lbcc . get_beta_y_theoretic_based ( theoretic_query [ plot_week , :], mu ) 1.) db_funcs.query_inst_combo queries database for closest image combinations to date observed 2.) db_funcs.query_var_val query fit parameters from database 3.) lbcc.get_beta_y_theoretic_based(theoretic_query[date_index, :], mu) calculate beta and y correction coefficients over time using theoretic fit parameters and mu values used for plotting beta and y over time 4.) lbcc.get_beta_y_theoretic_based(theoretic_query[plot_week, :], mu) calculate beta and y correction coefficients for a specific week using theoretic fit parameters and mu values used for plotting beta and y v. mu for a specific week Generate Histogram Plots This function queries the database for histograms and LBC fit parameters then generates plots of histograms before and after the LBC correction. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 def generate_histogram_plots ( db_session , hdf_data_dir , inst_list , hist_plot_query_time_min , hist_plot_query_time_max , n_hist_plots = 1 , n_mu_bins = 18 , n_intensity_bins = 200 , lat_band = [ - np . pi / 64. , np . pi / 64. ], log10 = True ): \"\"\" function to generate plots of histograms before and after limb-brightening \"\"\" pd_hist = db_funcs . query_hist ( db_session = db_session , meth_id = method_id [ 1 ], n_mu_bins = n_mu_bins , n_intensity_bins = n_intensity_bins , lat_band = np . array ( lat_band ) . tobytes (), time_min = hist_plot_query_time_min , time_max = hist_plot_query_time_max , instrument = query_instrument ) Plotting . Plot2d_Hist ( plot_hist , date_obs , instrument , intensity_bin_edges , mu_bin_edges , figure , plot_index ) original_los , lbcc_image , mu_indices , use_indices = iit_funcs . apply_lbc_correction ( db_session , hdf_data_dir , instrument , row , n_intensity_bins , R0 ) hist_lbcc = psi_d_types . create_lbcc_hist ( hdf_path , row . image_id , method_id [ 1 ], mu_bin_edges , intensity_bin_edges , lat_band , temp_hist ) Plotting . Plot_LBCC_Hists ( plot_hist , date_obs , instrument , intensity_bin_edges , mu_bin_edges , figure , plot_index ) 1.) db_funcs.query_hist queries database for histograms (from Histogram table) in specified date range 2.) Plotting.Plot2d_Hist plots 2D histogram with plot title and axes labels 3.) iit_funcs.apply_lbc_correction applies Limb-Brightening Correction to images and creates LBCCImage datatype 4.) psi_d_types.create_lbcc_hist create histogram datatype from lbcc histogram 5.) Plotting.Plot_LBCC_Hists plots original and LBC corrected 2D histograms","title":"Limb-Brightening Correction"},{"location":"ipp/lbc/#limb-brightening-correction","text":"Limb Brightening Correction (LBC) is the second step in the data pre-processing pipeline. The goal of LBC is to correct for brightening of structures that is dependent upon their distance from disk center.","title":"Limb-Brightening Correction"},{"location":"ipp/lbc/#examples-of-corrected-images","text":"These images of before and after applying LBC are from the different instruments on April 1, 2011. These can be enlarged by clicking image titles.","title":"Examples of Corrected Images"},{"location":"ipp/lbc/#aia-images","text":"Original AIA Image Corrected AIA Image Difference AIA Image","title":"AIA Images"},{"location":"ipp/lbc/#euvi-a-images","text":"Original STA Image Corrected STA Image Difference STA Image","title":"EUVI-A Images"},{"location":"ipp/lbc/#euvi-b-images","text":"Original STB Image Corrected STB Image Difference STB Image","title":"EUVI-B Images"},{"location":"ipp/lbc/#theoretical-analysis-pipeline","text":"","title":"Theoretical Analysis Pipeline"},{"location":"ipp/lbc/#compute-histograms-and-save-to-database","text":"This function computes 2D Histograms from processed images for use in the LBC process. It then saves these computed histograms to the database. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 def save_histograms ( db_session , hdf_data_dir , inst_list , hist_query_time_min , hist_query_time_max , n_mu_bins = 18 , n_intensity_bins = 200 , lat_band = [ - np . pi / 64. , np . pi / 64. ], log10 = True , R0 = 1.01 ): \"\"\" function to create and save histograms to database \"\"\" query_pd = db_funcs . query_euv_images ( db_session = db_session , time_min = hist_query_time_min , time_max = hist_query_time_max , instrument = query_instrument ) temp_hist = los_temp . mu_hist ( image_intensity_bin_edges , mu_bin_edges , lat_band = lat_band , log10 = log10 ) hist_lbcc = psi_d_types . create_lbcc_hist ( hdf_path , row . image_id , method_id [ 1 ], mu_bin_edges , image_intensity_bin_edges , lat_band , temp_hist ) db_funcs . add_hist ( db_session , hist_lbcc ) 1.) db_funcs.query_euv_images queries database for images (from EUV_Images table) in specified date range 2.) los_temp.mu_hist creates histogram based on number of mu and intensity bins 3.) psi_d_types.create_lbcc_hist create histogram datatype from lbcc histogram 4.) db_funcs.add_hist saves histograms to database (table Histogram) associating an image_id, meth_id, and basic information with histogram","title":"Compute Histograms and Save to Database"},{"location":"ipp/lbc/#calculate-and-save-theoretical-fit-parameters","text":"This function queries histograms from the database then calculates LBC fit parameters which are then saved in the database. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def calc_theoretic_fit ( db_session , inst_list , calc_query_time_min , calc_query_time_max , weekday = 0 , number_of_days = 180 , n_mu_bins = 18 , n_intensity_bins = 200 , lat_band = [ - np . pi / 64. , np . pi / 64. ], create = False ): \"\"\" function to calculate and save (to database) theoretic LBC fit parameters \"\"\" pd_hist = db_funcs . query_hist ( db_session = db_session , meth_id = method_id [ 1 ], n_mu_bins = n_mu_bins , n_intensity_bins = n_intensity_bins , lat_band = np . array ( lat_band ) . tobytes (), time_min = np . datetime64 ( min_date ) . astype ( datetime . datetime ), time_max = np . datetime64 ( max_date ) . astype ( datetime . datetime ), instrument = query_instrument ) optim_out_theo = optim . minimize ( lbcc . get_functional_sse , init_pars , args = ( hist_ref , hist_mat , mu_vec , intensity_bin_array , model ), method = \"BFGS\" ) db_funcs . store_lbcc_values ( db_session , pd_hist , meth_name , meth_desc , var_name , var_desc , date_index , inst_index , optim_vals = optim_vals_theo [ 0 : 6 ], results = results_theo , create = True ) 1.) db_funcs.query_hist queries database for histograms (from Histogram table) in specified date range 2.) optim.minimize use theoretical optimization method to calculate fit parameters 3.) db_funcs.store_lbcc_values save the six fit parameters to database using function store_lbcc_values creates image combination combo_id of image_ids and dates in Images_Combos table creates association between each image_id and combo_id in Image_Combo_Assoc table creates new method \u201cLBCC Theoretic\u201d with an associated meth_id in Meth_Defs table creates new variable definitions \u201cTheoVar\u201d + index with an associated var_id in Var_Defs table store variable value as float in Var_Vals table with associated combo_id, meth_id, and var_id","title":"Calculate and Save Theoretical Fit Parameters"},{"location":"ipp/lbc/#apply-limb-brightening-correction-and-plot-corrected-images","text":"This function queries the database for LBC fit parameters then applies them to specified images, plotting resulting images before and after the correction. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def apply_lbc_correction ( db_session , hdf_data_dir , inst_list , lbc_query_time_min , lbc_query_time_max , n_intensity_bins = 200 , R0 = 1.01 , n_images_plot = 1 , plot = False ): \"\"\" function to apply limb-brightening correction and plot images within a certain time frame \"\"\" image_pd = db_funcs . query_euv_images ( db_session = db_session , time_min = lbc_query_time_min , time_max = lbc_query_time_max , instrument = query_instrument ) combo_query = db_funcs . query_inst_combo ( db_session , lbc_query_time_min , lbc_query_time_max , meth_name , instrument ) original_los , lbcc_image , mu_indices , use_indices = apply_lbc ( db_session , hdf_data_dir , combo_query , image_row = row , n_intensity_bins = n_intensity_bins , R0 = R0 ) if plot : Plotting . PlotImage ( original_los , nfig = 100 + inst_index * 10 + index , title = \"Original LOS Image for \" + instrument ) Plotting . PlotCorrectedImage ( corrected_data = lbcc_image . lbcc_data , los_image = original_los , nfig = 200 + inst_index * 10 + index , title = \"Corrected LBCC Image for \" + instrument ) Plotting . PlotCorrectedImage ( corrected_data = original_los . data - lbcc_image . lbcc_data , los_image = original_los , nfig = 300 + inst_index * 10 + index , title = \"Difference Plot for \" + instrument ) 1.) db_funcs.query_euv_images queries database for images (from EUV_Images table) in specified date range 2.) db_funcs.query_inst_combo queries database for closest image combinations to date observed 3.) db_funcs.query_var_val queries database for variable values associated with specific image (from Var_Vals table) 4.) lbcc.get_beta_y_theoretic_continuous_1d_indices calculates 1d beta and y arrays for valid mu indices uses variable values from query in step two uses original los image to determine indices for correction 5.) corrected_lbc_data[use_indices] = 10 ** (beta1d * np.log10(original_los.data[use_indices]) + y1d) applies correction to image based off beta, y, and original data arrays 6.) Plotting.PlotImage and Plotting.PlotCorrectedImage plots original and corrected images, and difference between them","title":"Apply Limb-Brightening Correction and Plot Corrected Images"},{"location":"ipp/lbc/#apply-lbc","text":"This is a sub-step that applies the Limb-Brightening Corrrection to individual image and returns the correct LBCC Image. It is called during the third step of Limb-Brightening. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def apply_lbc ( db_session , hdf_data_dir , inst_combo_query , image_row , n_intensity_bins = 200 , R0 = 1.01 ): \"\"\" function to apply LBC to a specific image, returns corrected image \"\"\" db_sesh , meth_id , var_ids = db_funcs . get_method_id ( db_session , meth_name , meth_desc = None , var_names = None , var_descs = None , create = False ) original_los = psi_d_types . read_los_image ( hdf_path ) theoretic_query = db_funcs . query_var_val ( db_session , meth_name , date_obs = original_los . info [ 'date_string' ], inst_combo_query = inst_combo_query ) beta1d , y1d , mu_indices , use_indices = lbcc . get_beta_y_theoretic_continuous_1d_indices ( theoretic_query , los_image = original_los ) corrected_lbc_data [ use_indices ] = 10 ** ( beta1d * np . log10 ( original_los . data [ use_indices ]) + y1d ) lbcc_image = psi_d_types . create_lbcc_image ( hdf_path , corrected_lbc_data , image_id = image_row . image_id , meth_id = meth_id , intensity_bin_edges = intensity_bin_edges ) return original_los , lbcc_image , mu_indices , use_indices , theoretic_query 1.) db_funcs.get_method_id queries database for method id associated with method name 2.) psi_d_types.read_los_image reads in los image from database 3.) db_funcs.query_var_val queries database for variable values associated with specific image (from Var_Vals table) 4.) lbcc.get_beta_y_theoretic_continuous_1d_indices calculates 1d beta and y arrays for valid mu indices uses variable values from query in step two uses original los image to determine indices for correction 5.) corrected_lbc_data[use_indices] = 10 ** (beta1d * np.log10(original_los.data[use_indices]) + y1d) applies correction to image based off beta, y, and original data arrays 6.) psi_d_types.create_lbcc_image create LBCC Image datatype from corrected LBC data","title":"Apply LBC"},{"location":"ipp/lbc/#generate-plots-of-beta-and-y","text":"This function queries the database for LBC fit parameters then generates plots of Beta and y over time. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 def generate_theoretic_plots ( db_session , inst_list , plot_query_time_min , plot_query_time_max , weekday , image_out_path , year = '2011' , time_period = '6 Month' , plot_week = 0 , n_mu_bins = 18 ): \"\"\" function to generate plots of beta/y over time and beta/y v. mu \"\"\" combo_query = db_funcs . query_inst_combo ( db_session , plot_query_time_min , plot_query_time_max , meth_name , instrument ) theoretic_query [ date_index , :] = db_funcs . query_var_val ( db_session , meth_name , date_obs = np . datetime64 ( center_date ) . astype ( datetime . datetime ), inst_combo_query = inst_combo_query ) plot_beta [ mu_index , date_index ], plot_y [ mu_index , date_index ] = lbcc . get_beta_y_theoretic_based ( theoretic_query [ date_index , :], mu ) beta_y_v_mu [ index , :] = lbcc . get_beta_y_theoretic_based ( theoretic_query [ plot_week , :], mu ) 1.) db_funcs.query_inst_combo queries database for closest image combinations to date observed 2.) db_funcs.query_var_val query fit parameters from database 3.) lbcc.get_beta_y_theoretic_based(theoretic_query[date_index, :], mu) calculate beta and y correction coefficients over time using theoretic fit parameters and mu values used for plotting beta and y over time 4.) lbcc.get_beta_y_theoretic_based(theoretic_query[plot_week, :], mu) calculate beta and y correction coefficients for a specific week using theoretic fit parameters and mu values used for plotting beta and y v. mu for a specific week","title":"Generate Plots of Beta and y"},{"location":"ipp/lbc/#generate-histogram-plots","text":"This function queries the database for histograms and LBC fit parameters then generates plots of histograms before and after the LBC correction. The source code and example usage for this is found in the CHD GitHub and the generalized function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 def generate_histogram_plots ( db_session , hdf_data_dir , inst_list , hist_plot_query_time_min , hist_plot_query_time_max , n_hist_plots = 1 , n_mu_bins = 18 , n_intensity_bins = 200 , lat_band = [ - np . pi / 64. , np . pi / 64. ], log10 = True ): \"\"\" function to generate plots of histograms before and after limb-brightening \"\"\" pd_hist = db_funcs . query_hist ( db_session = db_session , meth_id = method_id [ 1 ], n_mu_bins = n_mu_bins , n_intensity_bins = n_intensity_bins , lat_band = np . array ( lat_band ) . tobytes (), time_min = hist_plot_query_time_min , time_max = hist_plot_query_time_max , instrument = query_instrument ) Plotting . Plot2d_Hist ( plot_hist , date_obs , instrument , intensity_bin_edges , mu_bin_edges , figure , plot_index ) original_los , lbcc_image , mu_indices , use_indices = iit_funcs . apply_lbc_correction ( db_session , hdf_data_dir , instrument , row , n_intensity_bins , R0 ) hist_lbcc = psi_d_types . create_lbcc_hist ( hdf_path , row . image_id , method_id [ 1 ], mu_bin_edges , intensity_bin_edges , lat_band , temp_hist ) Plotting . Plot_LBCC_Hists ( plot_hist , date_obs , instrument , intensity_bin_edges , mu_bin_edges , figure , plot_index ) 1.) db_funcs.query_hist queries database for histograms (from Histogram table) in specified date range 2.) Plotting.Plot2d_Hist plots 2D histogram with plot title and axes labels 3.) iit_funcs.apply_lbc_correction applies Limb-Brightening Correction to images and creates LBCCImage datatype 4.) psi_d_types.create_lbcc_hist create histogram datatype from lbcc histogram 5.) Plotting.Plot_LBCC_Hists plots original and LBC corrected 2D histograms","title":"Generate Histogram Plots"},{"location":"ipp/psf/","text":"PSF Deconvolution Page regarding PSF deconvolution.","title":"PSF Deconvolution"},{"location":"ipp/psf/#psf-deconvolution","text":"Page regarding PSF deconvolution.","title":"PSF Deconvolution"},{"location":"map/cmb/","text":"Combining Maps Maps are combined using a minimum intensity merge method. Maps are originally created for each instrument image individually then merged. There can be some points of overlap between different instrument maps and this is resolved by taking the data with the minimum intensity from each point of overlap. Coronal Hole data is then chosen based off which data points are used to create the original EUV maps. This method ensures that resulting maps are more continuous at seams. We also use a cutoff mu value to limit limb data distortion. In merging regions of overlap, we use data with a mu value greater than the cutoff value. In areas without overlap, any data available is used (mu cutoff of 0). Combine Maps Function The combine maps function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def combine_maps ( map_list , chd_map_list = None , mu_cutoff = 0.0 , mu_cut_over = None , del_mu = None ): \"\"\" function to combine maps from a list of PsiMap objects based on a mu_cutoff and minimum intensity merge Two methods to determine best minimum intensity merge - using mu cutoff values, or using del mu value return: combined EUV map, combined CHD map \"\"\" map_list [ ii ] . data [ map_list [ ii ] . mu < mu_cutoff ] = map_list [ ii ] . no_data_val if mu_cut_over is not None : overlap [:, :, ii ] = np . logical_and ( data_array [:, :, ii ] != map_list [ 0 ] . no_data_val , data_array [:, :, jj ] != map_list [ 0 ] . no_data_val ) good_index [:, :, ii ] = np . logical_or ( np . logical_and ( overlap [:, :, ii ], mu_array [:, :, ii ] >= mu_cut_over ), np . logical_and ( data_array [:, :, ii ] != map_list [ 0 ] . no_data_val , mu_array [:, :, ii ] >= mu_cutoff )) data_array [ np . logical_not ( good_index )] = float_info . max elif del_mu is not None : good_index [:, :, ii ] = mu_array [:, :, ii ] > ( max_mu - del_mu ) data_array [ np . logical_not ( good_index )] = float_info . max data_array [ data_array == map_list [ 0 ] . no_data_val ] = float_info . max map_index = np . argmin ( data_array , axis = 2 ) keep_data = data_array [ row_index , col_index , map_index ] keep_chd = chd_array [ row_index , col_index , map_index ] chd_map = psi_d_types . PsiMap ( keep_chd , map_list [ 0 ] . x , map_list [ 0 ] . y , mu = keep_mu , origin_image = keep_image , no_data_val = map_list [ 0 ] . no_data_val ) euv_map = psi_d_types . PsiMap ( keep_data , map_list [ 0 ] . x , map_list [ 0 ] . y , mu = keep_mu , origin_image = keep_image , no_data_val = map_list [ 0 ] . no_data_val ) return euv_map , chd_map 1.) map_list[ii].data[map_list[ii].mu < mu_cutoff] = map_list[ii].no_data_val for all pixels with mu < mu_cutoff, set intensity to no_data_val 2.1) np.logical_or(np.logical_and(overlap[:, :, ii], mu_array[:, :, ii] >= mu_cut_over), np.logical_and( data_array[:, :, ii] != map_list[0].no_data_val, mu_array[:, :, ii] >= mu_cutoff)) to determine \"good indices\" based of Caplan et. al. 2016: check for overlap, in areas of overlap choose data where mu > mu_cut_over in areas of no overlap, choose data where mu > mu_cutoff 2.2) mu_array[:, :, ii] > (max_mu - del_mu) determines \"good indices\" based off the value of del_mu 3.) data_array[np.logical_not(good_index)] = float_info.max, data_array[data_array == map_list[0].no_data_val] = float_info.max make poor mu pixels unusable to merge, make no_data_vals unusable to merge 4.) map_index = np.argmin(data_array, axis=2) find minimum intensity of remaining pixels 5.) keep_data = data_array[row_index, col_index, map_index], keep_data = data_array[row_index, col_index, map_index] choose data to use for the EUV and CHD map 6.) psi_d_types.PsiMap create new PsiMap object for both EUV and CHD combined maps","title":"Combining Maps"},{"location":"map/cmb/#combining-maps","text":"Maps are combined using a minimum intensity merge method. Maps are originally created for each instrument image individually then merged. There can be some points of overlap between different instrument maps and this is resolved by taking the data with the minimum intensity from each point of overlap. Coronal Hole data is then chosen based off which data points are used to create the original EUV maps. This method ensures that resulting maps are more continuous at seams. We also use a cutoff mu value to limit limb data distortion. In merging regions of overlap, we use data with a mu value greater than the cutoff value. In areas without overlap, any data available is used (mu cutoff of 0).","title":"Combining Maps"},{"location":"map/cmb/#combine-maps-function","text":"The combine maps function can be found here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def combine_maps ( map_list , chd_map_list = None , mu_cutoff = 0.0 , mu_cut_over = None , del_mu = None ): \"\"\" function to combine maps from a list of PsiMap objects based on a mu_cutoff and minimum intensity merge Two methods to determine best minimum intensity merge - using mu cutoff values, or using del mu value return: combined EUV map, combined CHD map \"\"\" map_list [ ii ] . data [ map_list [ ii ] . mu < mu_cutoff ] = map_list [ ii ] . no_data_val if mu_cut_over is not None : overlap [:, :, ii ] = np . logical_and ( data_array [:, :, ii ] != map_list [ 0 ] . no_data_val , data_array [:, :, jj ] != map_list [ 0 ] . no_data_val ) good_index [:, :, ii ] = np . logical_or ( np . logical_and ( overlap [:, :, ii ], mu_array [:, :, ii ] >= mu_cut_over ), np . logical_and ( data_array [:, :, ii ] != map_list [ 0 ] . no_data_val , mu_array [:, :, ii ] >= mu_cutoff )) data_array [ np . logical_not ( good_index )] = float_info . max elif del_mu is not None : good_index [:, :, ii ] = mu_array [:, :, ii ] > ( max_mu - del_mu ) data_array [ np . logical_not ( good_index )] = float_info . max data_array [ data_array == map_list [ 0 ] . no_data_val ] = float_info . max map_index = np . argmin ( data_array , axis = 2 ) keep_data = data_array [ row_index , col_index , map_index ] keep_chd = chd_array [ row_index , col_index , map_index ] chd_map = psi_d_types . PsiMap ( keep_chd , map_list [ 0 ] . x , map_list [ 0 ] . y , mu = keep_mu , origin_image = keep_image , no_data_val = map_list [ 0 ] . no_data_val ) euv_map = psi_d_types . PsiMap ( keep_data , map_list [ 0 ] . x , map_list [ 0 ] . y , mu = keep_mu , origin_image = keep_image , no_data_val = map_list [ 0 ] . no_data_val ) return euv_map , chd_map 1.) map_list[ii].data[map_list[ii].mu < mu_cutoff] = map_list[ii].no_data_val for all pixels with mu < mu_cutoff, set intensity to no_data_val 2.1) np.logical_or(np.logical_and(overlap[:, :, ii], mu_array[:, :, ii] >= mu_cut_over), np.logical_and( data_array[:, :, ii] != map_list[0].no_data_val, mu_array[:, :, ii] >= mu_cutoff)) to determine \"good indices\" based of Caplan et. al. 2016: check for overlap, in areas of overlap choose data where mu > mu_cut_over in areas of no overlap, choose data where mu > mu_cutoff 2.2) mu_array[:, :, ii] > (max_mu - del_mu) determines \"good indices\" based off the value of del_mu 3.) data_array[np.logical_not(good_index)] = float_info.max, data_array[data_array == map_list[0].no_data_val] = float_info.max make poor mu pixels unusable to merge, make no_data_vals unusable to merge 4.) map_index = np.argmin(data_array, axis=2) find minimum intensity of remaining pixels 5.) keep_data = data_array[row_index, col_index, map_index], keep_data = data_array[row_index, col_index, map_index] choose data to use for the EUV and CHD map 6.) psi_d_types.PsiMap create new PsiMap object for both EUV and CHD combined maps","title":"Combine Maps Function"},{"location":"map/int/","text":"Interpolation Currently use linear interpolation, working on other methods utilizing astropy package functionality.","title":"Interpolation"},{"location":"map/int/#interpolation","text":"Currently use linear interpolation, working on other methods utilizing astropy package functionality.","title":"Interpolation"},{"location":"map/map/","text":"Mapping Pipeline After the calculation of the image pre-processing parameters (LBC and IIT), the mapping process undergoes five main steps through which EUV Images are converted to EUV and CHD Maps. 1.) Selecting Images 2.) Apply Pre-Processing Corrections a.) generate moving average dates b.) query for image combos associated with dates c.) apply LBC d.) apply IIT 3.) Coronal Hole Detection 4.) Create Single Instrument Maps 5.) Combine Maps and Save to the Database Mapping Pipeline Functions Select Images The first step in map creation is querying the database for all EUV Images in the relevant time frame and creating a methods dataframe. These functions are database functions and the full code can be found here . 1 2 query_pd = db_funcs . query_euv_images ( db_session = db_session , time_min = query_time_min , time_max = query_time_max ) methods_list = db_funcs . generate_methdf ( query_pd ) 1.) db_funcs.query_euv_images queries the database for EUV Images between time_min and time_max 2.) db_funcs.generate_methdf generates an empty pandas dataframe to later store method information columns hold associated method and variable information Apply Pre-Processing Corrections Limb-Brightening and Inter-Instrument Transformation Corrections are applied to images. Due to memory and storage issues, the rest of the mapping pipeline is applied to images based off date to limit the amount of data stored in memory. Dates for Processing This function creates an array of moving average dates which are looped through to apply corrections. 1 2 3 4 5 6 7 def get_dates ( query_time_min , query_time_max , map_freq ): \"\"\" function to create moving average dates based on hourly frequency of map creation \"\"\" map_frequency = int (( query_time_max - query_time_min ) . seconds / 3600 / map_freq ) moving_avg_centers = np . array ([ np . datetime64 ( str ( query_time_min )) + ii * np . timedelta64 ( map_freq , 'h' ) for ii in range ( map_frequency + 1 )]) return moving_avg_centers 1.) int((query_time_max - query_time_min).seconds / 3600 / map_freq) convert the map_freq integer to hours 2.) np.array(...) create moving average centers array based upon map frequency Query for Image Combos This function creates lists of combo queries for each instrument. It returns lists for LBC and IIT combo queries. 1 2 3 4 5 6 7 8 9 10 def get_inst_combos ( db_session , inst_list , time_min , time_max ): \"\"\" function to create instrument based lists of combo queries for image pre-processing \"\"\" for inst_index , instrument in enumerate ( inst_list ): lbc_combo = db_funcs . query_inst_combo ( db_session , time_min - datetime . timedelta ( days = 180 ), time_max + datetime . timedelta ( days = 180 ), meth_name = 'LBCC' , instrument = instrument ) iit_combo = db_funcs . query_inst_combo ( db_session , time_min - datetime . timedelta ( days = 180 ), time_max + datetime . timedelta ( days = 180 ), meth_name = 'IIT' , instrument = instrument ) lbc_combo_query [ inst_index ] = lbc_combo iit_combo_query [ inst_index ] = iit_combo return lbc_combo_query , iit_combo_query 1.) db_funcs.query_inst_combo queries database for image combinations for specific instrument within the 180 day range does this for both the LBC and IIT methods 2.) lbc_combo_query[inst_index] = lbc_combo add the combo query to the combo query list at the inst_index does this for both the LBC and IIT methods Apply Image Corrections This function applies the image pre-processing corrections to images of the center date in question. It returns a list of processed IIT Images and reference values for Coronal Hole Detection. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def apply_ipp ( db_session , center_date , query_pd , inst_list , hdf_data_dir , lbc_combo_query , iit_combo_query , methods_list , n_intensity_bins = 200 , R0 = 1.01 ): \"\"\" function to apply image pre-processing (limb-brightening, inter-instrument transformation) corrections to EUV images for creation of maps \"\"\" ref_alpha , ref_x = db_funcs . query_var_val ( db_session , meth_name = 'IIT' , date_obs = date_time , inst_combo_query = iit_combo_query [ sta_ind ]) for inst_ind , instrument in enumerate ( inst_list ): los_list [ inst_ind ], lbcc_image , mu_indices , use_ind , theoretic_query = lbcc_funcs . apply_lbc ( db_session , hdf_data_dir , lbc_combo_query [ inst_ind ], image_row = image_row , n_intensity_bins = n_intensity_bins , R0 = R0 ) lbcc_image , iit_list [ inst_ind ], use_indices [ inst_ind ], alpha , x = iit_funcs . apply_iit ( db_session , iit_combo_query [ inst_ind ], lbcc_image , use_ind , los_list [ inst_ind ], R0 = R0 ) ipp_method = { 'meth_name' : ( \"LBCC\" , \"IIT\" ), 'meth_description' :[ \"LBCC Theoretic Fit Method\" , \"IIT Fit Method\" ] , 'var_name' : ( \"LBCC\" , \"IIT\" ), 'var_description' : ( \" \" , \" \" )} methods_list [ inst_ind ] = methods_list [ inst_ind ] . append ( pd . DataFrame ( data = ipp_method ), sort = False ) return date_pd , los_list , iit_list , use_indices , methods_list , ref_alpha , ref_x 1.) db_funcs.query_var_val this is a database function to query variable values ref_alpha and ref_x are the IIT values for the STA Image at this date; these values are used to calculate threshold values for CH Detection 2.) lbcc_funcs.apply_lbc applies Limb-Brightening Correction to images and creates LBCCImage datatype 3.) iit_funcs.apply_iit applies Inter-Instrument Transformation Correction to images and creates IITImage datatype which is added to the iit_list 4.) methods_list[inst_ind].append add the LBC and IIT Correction methods to the methods dataframe Coronal Hole Detection This function applies the Fortran Coronal Hole Detection algorithm and returns a list of CHD Images for mapping. 1 2 3 4 5 6 7 8 9 10 11 def chd ( iit_list , los_list , use_indices , inst_list , thresh1 , thresh2 , ref_alpha , ref_x , nc , iters ): \"\"\" function to apply CHD algorithm and create list of CHD Images from a list of IIT Images \"\"\" for inst_ind , instrument in enumerate ( inst_list ): t1 = thresh1 * ref_alpha + ref_x t2 = thresh2 * ref_alpha + ref_x ezseg_output , iters_used = ezsegwrapper . ezseg ( np . log10 ( image_data ), use_chd , nx , ny , t1 , t2 , nc , iters ) chd_image_list [ inst_ind ] = datatypes . create_chd_image ( los_list [ inst_ind ], chd_result ) return chd_image_list 1.) t1 = thresh1 * ref_alpha + ref_x re-calculate threshold 1 and 2 values based off the EUVI-A IIT values 2.) ezsegwrapper.ezseg call the python wrapper function for the CH Detection algorithm 3.) datatypes.create_chd_image create CHD Image datatype and add to the CHD Image list for mapping Single Maps This function creates single instrument maps from both IIT Images and CHD Images. This mapping is done through linear interpolation onto a Carrington map. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def create_singles_maps ( inst_list , date_pd , iit_list , chd_image_list , methods_list , map_x = None , map_y = None , R0 = 1.01 ): \"\"\" function to map single instrument images to a Carrington map \"\"\" for inst_ind , instrument in enumerate ( inst_list ): map_list [ inst_ind ] = iit_list [ inst_ind ] . interp_to_map ( R0 = R0 , map_x = map_x , map_y = map_y , image_num = image_row . image_id ) chd_map_list [ inst_ind ] = chd_image_list [ inst_ind ] . interp_to_map ( R0 = R0 , map_x = map_x , map_y = map_y , image_num = image_row . image_id ) interp_method = { 'meth_name' : ( \"Im2Map_Lin_Interp_1\" ,), 'meth_description' :[ \"Use SciPy.RegularGridInterpolator() to linearly interpolate from an Image to a Map\" ] * 1 , 'var_name' : ( \"R0\" ,), 'var_description' : ( \"Solar radii\" ,), 'var_val' : ( R0 ,)} methods_list [ inst_ind ] = methods_list [ inst_ind ] . append ( pd . DataFrame ( data = interp_method ), sort = False ) map_list [ inst_ind ] . append_method_info ( methods_list [ inst_ind ]) chd_map_list [ inst_ind ] . append_method_info ( methods_list [ inst_ind ]) return map_list , chd_map_list , methods_list , image_info , map_info 1.) iit_list[inst_ind].interp_to_map, chd_image_list[inst_ind].interp_to_map interpolate IIT corrected, CHD image to Carrington map using linear interpolation 2.) methods_list[inst_ind].append append linear interpolation mapping method to the methods list 3.) map_list[inst_ind].append_method_info, chd_map_list[inst_ind].append_method_info append method information to the both the EUV and CHD map lists Combine Maps This function creates combined EUV and CHD maps from individual instruments maps. Then saves method, map parameter values, and maps to the database. Maps are combined using a Minimum Intensity Merge. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def create_combined_maps ( db_session , map_data_dir , map_list , chd_map_list , methods_list , image_info , map_info , mu_cut_over = None , del_mu = None , mu_cutoff = 0.0 ): \"\"\" function to create combined EUV and CHD maps and save to database with associated method information \"\"\" if del_mu is not None : euv_combined , chd_combined = combine_maps ( euv_maps , chd_maps , del_mu = del_mu , mu_cutoff = mu_cutoff ) combined_method = { 'meth_name' : ( \"Min-Int-Merge_1\" , \"Min-Int-Merge_1\" ), 'meth_description' :[ \"Minimum intensity merge: using del mu\" ] * 2 , 'var_name' : ( \"mu_cutoff\" , \"del_mu\" ), 'var_description' : ( \"lower mu cutoff value\" , \"max acceptable mu range\" ), 'var_val' : ( mu_cutoff , del_mu )} else : euv_combined , chd_combined = combine_maps ( euv_maps , chd_maps , mu_cut_over = mu_cut_over , mu_cutoff = mu_cutoff ) combined_method = { 'meth_name' : ( \"Min-Int-Merge_2\" , \"Min-Int-Merge_2\" ), 'meth_description' :[ \"Minimum intensity merge: based on Caplan et. al.\" ] * 2 , 'var_name' : ( \"mu_cutoff\" , \"mu_cut_over\" ), 'var_description' : ( \"lower mu cutoff value\" , \"mu cutoff value in areas of overlap\" ), 'var_val' : ( mu_cutoff , mu_cut_over )} euv_combined . append_method_info ( methods_list ) euv_combined . append_method_info ( pd . DataFrame ( data = combined_method )) euv_combined . append_image_info ( image_info ) euv_combined . append_map_info ( map_info ) chd_combined . append_method_info ( methods_list ) chd_combined . append_method_info ( pd . DataFrame ( data = combined_method )) chd_combined . append_image_info ( image_info ) chd_combined . append_map_info ( map_info ) Plotting . PlotMap ( euv_combined , nfig = \"EUV Combined map for: \" + str ( euv_combined . image_info . date_obs [ 0 ]), title = \"Minimum Intensity Merge Map \\n Date: \" + str ( euv_combined . image_info . date_obs [ 0 ])) Plotting . PlotMap ( euv_combined , nfig = \"EUV/CHD Combined map for: \" + str ( euv_combined . image_info . date_obs [ 0 ]), title = \"Minimum Intensity EUV/CHD Merge Map \\n Date: \" + str ( euv_combined . image_info . date_obs [ 0 ])) Plotting . PlotMap ( chd_combined , nfig = \"EUV/CHD Combined map for: \" + str ( chd_combined . image_info . date_obs [ 0 ]), title = \"Minimum Intensity EUV/CHD Merge Map \\n Date: \" + str ( chd_combined . image_info . date_obs [ 0 ]), map_type = 'CHD' ) euv_combined . write_to_file ( map_data_dir , map_type = 'synoptic_euv' , filename = None , db_session = db_session ) chd_combined . write_to_file ( map_data_dir , map_type = 'synoptic_chd' , filename = None , db_session = db_session ) return euv_combined , chd_combined 1.) combine_maps function that combines EUV and CHD maps using a minimum intensity merge there are currently two implemented methods for the minimum intensity merge depending on initial input parameters 2.) euv_combined.append_method_info, euv_combined.append_image_info, euv_combined.append_map_info append methods list and combination method information to the both the EUV and CHD combined maps appends image and map info to combined maps, used for database storage 3.) Plotting.PlotMap plot the combined EUV and CHD maps 4.) euv_combined.write_to_file, chd_combined.write_to_file PSI Map function that writes the map to file and saves to the database using function add_map_dbase_record generates filename for map based off base path and map type creates method combination of LBC, IIT, Interpolation, and Minimum Intensity Merge creates Image Combination associated with each method stores map variable values (R0, mu_cutoff, del_mu/mu_cut_over) in database Var Vals Map table stores map information and filename in EUV Maps table","title":"Mapping Pipeline"},{"location":"map/map/#mapping-pipeline","text":"After the calculation of the image pre-processing parameters (LBC and IIT), the mapping process undergoes five main steps through which EUV Images are converted to EUV and CHD Maps. 1.) Selecting Images 2.) Apply Pre-Processing Corrections a.) generate moving average dates b.) query for image combos associated with dates c.) apply LBC d.) apply IIT 3.) Coronal Hole Detection 4.) Create Single Instrument Maps 5.) Combine Maps and Save to the Database","title":"Mapping Pipeline"},{"location":"map/map/#mapping-pipeline-functions","text":"","title":"Mapping Pipeline Functions"},{"location":"map/map/#select-images","text":"The first step in map creation is querying the database for all EUV Images in the relevant time frame and creating a methods dataframe. These functions are database functions and the full code can be found here . 1 2 query_pd = db_funcs . query_euv_images ( db_session = db_session , time_min = query_time_min , time_max = query_time_max ) methods_list = db_funcs . generate_methdf ( query_pd ) 1.) db_funcs.query_euv_images queries the database for EUV Images between time_min and time_max 2.) db_funcs.generate_methdf generates an empty pandas dataframe to later store method information columns hold associated method and variable information","title":"Select Images"},{"location":"map/map/#apply-pre-processing-corrections","text":"Limb-Brightening and Inter-Instrument Transformation Corrections are applied to images. Due to memory and storage issues, the rest of the mapping pipeline is applied to images based off date to limit the amount of data stored in memory.","title":"Apply Pre-Processing Corrections"},{"location":"map/map/#dates-for-processing","text":"This function creates an array of moving average dates which are looped through to apply corrections. 1 2 3 4 5 6 7 def get_dates ( query_time_min , query_time_max , map_freq ): \"\"\" function to create moving average dates based on hourly frequency of map creation \"\"\" map_frequency = int (( query_time_max - query_time_min ) . seconds / 3600 / map_freq ) moving_avg_centers = np . array ([ np . datetime64 ( str ( query_time_min )) + ii * np . timedelta64 ( map_freq , 'h' ) for ii in range ( map_frequency + 1 )]) return moving_avg_centers 1.) int((query_time_max - query_time_min).seconds / 3600 / map_freq) convert the map_freq integer to hours 2.) np.array(...) create moving average centers array based upon map frequency","title":"Dates for Processing"},{"location":"map/map/#query-for-image-combos","text":"This function creates lists of combo queries for each instrument. It returns lists for LBC and IIT combo queries. 1 2 3 4 5 6 7 8 9 10 def get_inst_combos ( db_session , inst_list , time_min , time_max ): \"\"\" function to create instrument based lists of combo queries for image pre-processing \"\"\" for inst_index , instrument in enumerate ( inst_list ): lbc_combo = db_funcs . query_inst_combo ( db_session , time_min - datetime . timedelta ( days = 180 ), time_max + datetime . timedelta ( days = 180 ), meth_name = 'LBCC' , instrument = instrument ) iit_combo = db_funcs . query_inst_combo ( db_session , time_min - datetime . timedelta ( days = 180 ), time_max + datetime . timedelta ( days = 180 ), meth_name = 'IIT' , instrument = instrument ) lbc_combo_query [ inst_index ] = lbc_combo iit_combo_query [ inst_index ] = iit_combo return lbc_combo_query , iit_combo_query 1.) db_funcs.query_inst_combo queries database for image combinations for specific instrument within the 180 day range does this for both the LBC and IIT methods 2.) lbc_combo_query[inst_index] = lbc_combo add the combo query to the combo query list at the inst_index does this for both the LBC and IIT methods","title":"Query for Image Combos"},{"location":"map/map/#apply-image-corrections","text":"This function applies the image pre-processing corrections to images of the center date in question. It returns a list of processed IIT Images and reference values for Coronal Hole Detection. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def apply_ipp ( db_session , center_date , query_pd , inst_list , hdf_data_dir , lbc_combo_query , iit_combo_query , methods_list , n_intensity_bins = 200 , R0 = 1.01 ): \"\"\" function to apply image pre-processing (limb-brightening, inter-instrument transformation) corrections to EUV images for creation of maps \"\"\" ref_alpha , ref_x = db_funcs . query_var_val ( db_session , meth_name = 'IIT' , date_obs = date_time , inst_combo_query = iit_combo_query [ sta_ind ]) for inst_ind , instrument in enumerate ( inst_list ): los_list [ inst_ind ], lbcc_image , mu_indices , use_ind , theoretic_query = lbcc_funcs . apply_lbc ( db_session , hdf_data_dir , lbc_combo_query [ inst_ind ], image_row = image_row , n_intensity_bins = n_intensity_bins , R0 = R0 ) lbcc_image , iit_list [ inst_ind ], use_indices [ inst_ind ], alpha , x = iit_funcs . apply_iit ( db_session , iit_combo_query [ inst_ind ], lbcc_image , use_ind , los_list [ inst_ind ], R0 = R0 ) ipp_method = { 'meth_name' : ( \"LBCC\" , \"IIT\" ), 'meth_description' :[ \"LBCC Theoretic Fit Method\" , \"IIT Fit Method\" ] , 'var_name' : ( \"LBCC\" , \"IIT\" ), 'var_description' : ( \" \" , \" \" )} methods_list [ inst_ind ] = methods_list [ inst_ind ] . append ( pd . DataFrame ( data = ipp_method ), sort = False ) return date_pd , los_list , iit_list , use_indices , methods_list , ref_alpha , ref_x 1.) db_funcs.query_var_val this is a database function to query variable values ref_alpha and ref_x are the IIT values for the STA Image at this date; these values are used to calculate threshold values for CH Detection 2.) lbcc_funcs.apply_lbc applies Limb-Brightening Correction to images and creates LBCCImage datatype 3.) iit_funcs.apply_iit applies Inter-Instrument Transformation Correction to images and creates IITImage datatype which is added to the iit_list 4.) methods_list[inst_ind].append add the LBC and IIT Correction methods to the methods dataframe","title":"Apply Image Corrections"},{"location":"map/map/#coronal-hole-detection","text":"This function applies the Fortran Coronal Hole Detection algorithm and returns a list of CHD Images for mapping. 1 2 3 4 5 6 7 8 9 10 11 def chd ( iit_list , los_list , use_indices , inst_list , thresh1 , thresh2 , ref_alpha , ref_x , nc , iters ): \"\"\" function to apply CHD algorithm and create list of CHD Images from a list of IIT Images \"\"\" for inst_ind , instrument in enumerate ( inst_list ): t1 = thresh1 * ref_alpha + ref_x t2 = thresh2 * ref_alpha + ref_x ezseg_output , iters_used = ezsegwrapper . ezseg ( np . log10 ( image_data ), use_chd , nx , ny , t1 , t2 , nc , iters ) chd_image_list [ inst_ind ] = datatypes . create_chd_image ( los_list [ inst_ind ], chd_result ) return chd_image_list 1.) t1 = thresh1 * ref_alpha + ref_x re-calculate threshold 1 and 2 values based off the EUVI-A IIT values 2.) ezsegwrapper.ezseg call the python wrapper function for the CH Detection algorithm 3.) datatypes.create_chd_image create CHD Image datatype and add to the CHD Image list for mapping","title":"Coronal Hole Detection"},{"location":"map/map/#single-maps","text":"This function creates single instrument maps from both IIT Images and CHD Images. This mapping is done through linear interpolation onto a Carrington map. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def create_singles_maps ( inst_list , date_pd , iit_list , chd_image_list , methods_list , map_x = None , map_y = None , R0 = 1.01 ): \"\"\" function to map single instrument images to a Carrington map \"\"\" for inst_ind , instrument in enumerate ( inst_list ): map_list [ inst_ind ] = iit_list [ inst_ind ] . interp_to_map ( R0 = R0 , map_x = map_x , map_y = map_y , image_num = image_row . image_id ) chd_map_list [ inst_ind ] = chd_image_list [ inst_ind ] . interp_to_map ( R0 = R0 , map_x = map_x , map_y = map_y , image_num = image_row . image_id ) interp_method = { 'meth_name' : ( \"Im2Map_Lin_Interp_1\" ,), 'meth_description' :[ \"Use SciPy.RegularGridInterpolator() to linearly interpolate from an Image to a Map\" ] * 1 , 'var_name' : ( \"R0\" ,), 'var_description' : ( \"Solar radii\" ,), 'var_val' : ( R0 ,)} methods_list [ inst_ind ] = methods_list [ inst_ind ] . append ( pd . DataFrame ( data = interp_method ), sort = False ) map_list [ inst_ind ] . append_method_info ( methods_list [ inst_ind ]) chd_map_list [ inst_ind ] . append_method_info ( methods_list [ inst_ind ]) return map_list , chd_map_list , methods_list , image_info , map_info 1.) iit_list[inst_ind].interp_to_map, chd_image_list[inst_ind].interp_to_map interpolate IIT corrected, CHD image to Carrington map using linear interpolation 2.) methods_list[inst_ind].append append linear interpolation mapping method to the methods list 3.) map_list[inst_ind].append_method_info, chd_map_list[inst_ind].append_method_info append method information to the both the EUV and CHD map lists","title":"Single Maps"},{"location":"map/map/#combine-maps","text":"This function creates combined EUV and CHD maps from individual instruments maps. Then saves method, map parameter values, and maps to the database. Maps are combined using a Minimum Intensity Merge. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def create_combined_maps ( db_session , map_data_dir , map_list , chd_map_list , methods_list , image_info , map_info , mu_cut_over = None , del_mu = None , mu_cutoff = 0.0 ): \"\"\" function to create combined EUV and CHD maps and save to database with associated method information \"\"\" if del_mu is not None : euv_combined , chd_combined = combine_maps ( euv_maps , chd_maps , del_mu = del_mu , mu_cutoff = mu_cutoff ) combined_method = { 'meth_name' : ( \"Min-Int-Merge_1\" , \"Min-Int-Merge_1\" ), 'meth_description' :[ \"Minimum intensity merge: using del mu\" ] * 2 , 'var_name' : ( \"mu_cutoff\" , \"del_mu\" ), 'var_description' : ( \"lower mu cutoff value\" , \"max acceptable mu range\" ), 'var_val' : ( mu_cutoff , del_mu )} else : euv_combined , chd_combined = combine_maps ( euv_maps , chd_maps , mu_cut_over = mu_cut_over , mu_cutoff = mu_cutoff ) combined_method = { 'meth_name' : ( \"Min-Int-Merge_2\" , \"Min-Int-Merge_2\" ), 'meth_description' :[ \"Minimum intensity merge: based on Caplan et. al.\" ] * 2 , 'var_name' : ( \"mu_cutoff\" , \"mu_cut_over\" ), 'var_description' : ( \"lower mu cutoff value\" , \"mu cutoff value in areas of overlap\" ), 'var_val' : ( mu_cutoff , mu_cut_over )} euv_combined . append_method_info ( methods_list ) euv_combined . append_method_info ( pd . DataFrame ( data = combined_method )) euv_combined . append_image_info ( image_info ) euv_combined . append_map_info ( map_info ) chd_combined . append_method_info ( methods_list ) chd_combined . append_method_info ( pd . DataFrame ( data = combined_method )) chd_combined . append_image_info ( image_info ) chd_combined . append_map_info ( map_info ) Plotting . PlotMap ( euv_combined , nfig = \"EUV Combined map for: \" + str ( euv_combined . image_info . date_obs [ 0 ]), title = \"Minimum Intensity Merge Map \\n Date: \" + str ( euv_combined . image_info . date_obs [ 0 ])) Plotting . PlotMap ( euv_combined , nfig = \"EUV/CHD Combined map for: \" + str ( euv_combined . image_info . date_obs [ 0 ]), title = \"Minimum Intensity EUV/CHD Merge Map \\n Date: \" + str ( euv_combined . image_info . date_obs [ 0 ])) Plotting . PlotMap ( chd_combined , nfig = \"EUV/CHD Combined map for: \" + str ( chd_combined . image_info . date_obs [ 0 ]), title = \"Minimum Intensity EUV/CHD Merge Map \\n Date: \" + str ( chd_combined . image_info . date_obs [ 0 ]), map_type = 'CHD' ) euv_combined . write_to_file ( map_data_dir , map_type = 'synoptic_euv' , filename = None , db_session = db_session ) chd_combined . write_to_file ( map_data_dir , map_type = 'synoptic_chd' , filename = None , db_session = db_session ) return euv_combined , chd_combined 1.) combine_maps function that combines EUV and CHD maps using a minimum intensity merge there are currently two implemented methods for the minimum intensity merge depending on initial input parameters 2.) euv_combined.append_method_info, euv_combined.append_image_info, euv_combined.append_map_info append methods list and combination method information to the both the EUV and CHD combined maps appends image and map info to combined maps, used for database storage 3.) Plotting.PlotMap plot the combined EUV and CHD maps 4.) euv_combined.write_to_file, chd_combined.write_to_file PSI Map function that writes the map to file and saves to the database using function add_map_dbase_record generates filename for map based off base path and map type creates method combination of LBC, IIT, Interpolation, and Minimum Intensity Merge creates Image Combination associated with each method stores map variable values (R0, mu_cutoff, del_mu/mu_cut_over) in database Var Vals Map table stores map information and filename in EUV Maps table","title":"Combine Maps"}]}